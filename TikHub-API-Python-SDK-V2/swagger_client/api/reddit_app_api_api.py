# coding: utf-8

"""
    TikHub Douyin/TikTok/Xiaohongshu/Lemon8/Bilibili/Sora2/Kuaishou/Pipixia/Weibo/WeChat/Instagram/YouTube/Twitter/Threads/Reddit/Zhihu/Captcha Solver/Temp Mail API

     ----  #### ğŸ“‹ Release Information/å‘å¸ƒä¿¡æ¯ - **ğŸ”¢ Version/ç‰ˆæœ¬**: `V5.3.2` - **ğŸ•’ Update Time/æ›´æ–°æ—¶é—´**: `2026-02-23` - **ğŸ–¥ï¸ Environment/ç¯å¢ƒ**: `Production` - **ğŸ”— Base URL/åŸºç¡€è·¯å¾„**: `https://api.tikhub.io`  #### ğŸŒ Basic HTTP Setup/åŸºæœ¬HTTPè®¾ç½® - **ğŸ“ HTTP Method/è¯·æ±‚æ–¹æ³•**: `GET`ã€`POST` - **ğŸ”„ Retry on Error/é”™è¯¯é‡è¯•**: `Max Retry: 3` - **â±ï¸ Timeout/è¶…æ—¶**: `>=30s and <=60s` - **âš¡ Rate Limit/é€Ÿç‡é™åˆ¶**: `QPS: 10/Second`  ----  ğŸ“¢ **é‡è¦æé†’ï¼šåŸŸåè®¿é—®ä¼˜åŒ–ï¼ˆé€‚ç”¨äºä¸­å›½å¤§é™†ç”¨æˆ·ï¼‰**  ç”±äºä¸»åŸŸå `api.tikhub.io` åœ¨ä¸­å›½å¤§é™†è¢«é•¿åŸé˜²ç«å¢™æ‹¦æˆªï¼Œ**è¯·ä¸­å›½å¤§é™†ç”¨æˆ·æ”¹ç”¨æ–°åŸŸåè¿›è¡Œè¯·æ±‚**ï¼š  * ğŸ‡¨ğŸ‡³ **å¤§é™†ç”¨æˆ·è¯·ä½¿ç”¨**ï¼š`https://api.tikhub.dev`ï¼ˆæ— éœ€ä»£ç†ï¼Œç›´æ¥å¯ç”¨ï¼‰ * ğŸŒ **éå¤§é™†ç”¨æˆ·ç»§ç»­ä½¿ç”¨**ï¼š`https://api.tikhub.io`  æ¥å£è·¯å¾„å’Œå‚æ•°ä¿æŒä¸å˜ï¼Œä»…éœ€æ›¿æ¢åŸŸåå³å¯ã€‚**è¯·å‹¿è·¨åŒºä½¿ç”¨ï¼Œä¼šå½±å“è®¿é—®é€Ÿåº¦ã€‚**  ----  #### ğŸ”— Useful Links / æœ‰ç”¨çš„é“¾æ¥  - ğŸ¡ **Home**: [https://www.tikhub.io](https://www.tikhub.io) - ğŸ™ **GitHub Organization** (ä»£ç ä»“åº“/Repositories): [https://github.com/TikHub](https://github.com/TikHub) - ğŸ›  **Python SDK V1** (å¼€å‘å¥—ä»¶/SDK): [https://github.com/TikHub/TikHub-API-Python-SDK](https://github.com/TikHub/TikHub-API-Python-SDK) - ğŸ›  **Python SDK V2** (å¼€å‘å¥—ä»¶/SDK): [https://github.com/TikHub/TikHub-API-Python-SDK-V2](https://github.com/TikHub/TikHub-API-Python-SDK-V2) - ğŸ“¥ **Multi-Functional Downloader** (å·¥å…·/Utilities): [https://github.com/TikHub/TikHub-Multi-Functional-Downloader](https://github.com/TikHub/TikHub-Multi-Functional-Downloader) - ğŸ–¥ï¸ **API Demo** (ç¤ºä¾‹é¡¹ç›®/Demo Project): [https://github.com/TikHub/TikHub-API-Demo](https://github.com/TikHub/TikHub-API-Demo) - ğŸ“œ **Swagger UI** (æ¥å£æ–‡æ¡£/API Documentation): [https://api.tikhub.io](https://api.tikhub.io) - ğŸ“š **Apifox UI** (æ¥å£æ–‡æ¡£/API Documentation): [https://docs.tikhub.io](https://docs.tikhub.io) - ğŸ§ª **API Playground** (æ¥å£æµ‹è¯•/API Testing): [https://app.apifox.com/project/4705614](https://app.apifox.com/project/4705614) - ğŸ“ˆ **API Status Monitor** (æœåŠ¡ç›‘æ§/Service Monitoring): [https://monitor.tikhub.io](https://monitor.tikhub.io) - ğŸ’¬ **Discord Server** (å®¢æœ/Support): [https://discord.gg/aMEAS8Xsvz](https://discord.gg/aMEAS8Xsvz) - âœ¨ **X.com** (æ›´æ–°/Updates): [https://x.com/TikHubio](https://x.com/TikHubio)  ----  #### ğŸ“ å¤‡æ³¨ - ğŸŒ TikHub API æ˜¯ä¸€ä¸ªå¤šç¤¾äº¤åª’ä½“æ•°æ®åˆ†æå¹³å°ï¼Œä¸ºå¼€å‘è€…æä¾›ä»¥ä¸‹æ•°æ®æ¥å£æœåŠ¡ï¼Œå¹¶ä¸”è¿˜åœ¨ä¸æ–­æ›´æ–°ä¸­ï¼š     - ğŸ“± [æŠ–éŸ³ç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-Web-API)     - ğŸ“± [æŠ–éŸ³App V1æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-App-V1-API) - ï¼ˆå·²å¼ƒç”¨å¹¶ä¸”ä¸‹æ¶æ¥å£æ–‡æ¡£ï¼Œè¯·ä½¿ç”¨æ–°ç‰ˆæ¥å£ï¼‰     - ğŸ“± [æŠ–éŸ³App V2æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-App-V2-API) - ï¼ˆå·²å¼ƒç”¨å¹¶ä¸”ä¸‹æ¶æ¥å£æ–‡æ¡£ï¼Œè¯·ä½¿ç”¨æ–°ç‰ˆæ¥å£ï¼‰     - ğŸ“± [æŠ–éŸ³App V3æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-App-V3-API)     - ğŸ”¥ [æŠ–éŸ³æœç´¢æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-Search-API)     - ğŸ”¥ [æŠ–éŸ³çƒ­ç‚¹æ¦œæ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-Billboard-API)     - â­ [æŠ–éŸ³æ˜Ÿå›¾æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-Xingtu-API)     - â­ [æŠ–éŸ³æ˜Ÿå›¾V2æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-Xingtu-V2-API)     - ğŸ‘¨â€ğŸ¨ [æŠ–éŸ³åˆ›ä½œè€…æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-Creator-API)     - ğŸ‘¨â€ğŸ¨ [æŠ–éŸ³åˆ›ä½œè€… V2æ•°æ®æ¥å£](https://api.tikhub.io/#/Douyin-Creator-V2-API) - ï¼ˆéœ€è¦ç”¨æˆ·Cookieï¼Œå¯è·å–ä½œå“æµé‡æ€»è§ˆç­‰æ•°æ®ï¼‰     - ğŸµ [TikTokç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/TikTok-Web-API)     - ğŸµ [TikTok App V2æ•°æ®æ¥å£](https://api.tikhub.io/#/TikTok-App-V2-API) - ï¼ˆå·²å¼ƒç”¨å¹¶ä¸”ä¸‹æ¶æ¥å£æ–‡æ¡£ï¼Œè¯·ä½¿ç”¨æ–°ç‰ˆæ¥å£ï¼‰     - ğŸµ [TikTok App V3æ•°æ®æ¥å£](https://api.tikhub.io/#/TikTok-App-V3-API)     - ğŸ‘¨â€ğŸ¨ [TikTokåˆ›ä½œè€…æ•°æ®æ¥å£ - ç”µå•†](https://api.tikhub.io/#/TikTok-Creator-API)     - ğŸµ [TikTokæ•°æ®åˆ†ææ¥å£ - MCN](https://api.tikhub.io/#/TikTok-Analytics-API)     - ğŸµ [TikTokå•†åŸç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/TikTok-Shop-Web-API)     - ğŸµ [TikTokå¹¿å‘Šåˆ›æ„ä¸­å¿ƒæ•°æ®æ¥å£ - Ads](https://api.tikhub.io/#/TikTok-Ads-API)     - ğŸ‰ [è¥¿ç“œè§†é¢‘App V2æ•°æ®æ¥å£](https://api.tikhub.io/#/Xigua-App-V2-API)     - ğŸ“• [å°çº¢ä¹¦ç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/Xiaohongshu-Web-API)     - ğŸ“• [å°çº¢ä¹¦ç½‘é¡µç‰ˆ V2æ•°æ®æ¥å£](https://api.tikhub.io/#/Xiaohongshu-Web-V2-API)     - ğŸ“• [å°çº¢ä¹¦Appæ•°æ®æ¥å£](https://api.tikhub.io/#/Xiaohongshu-App-API)     - ğŸ‹ [Lemon8 Appæ•°æ®æ¥å£](https://api.tikhub.io/#/Lemon8-App-API)     - ğŸ“º [å“”å“©å“”å“©ç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/Bilibili-Web-API)     - ğŸ“º [å“”å“©å“”å“©Appæ•°æ®æ¥å£](https://api.tikhub.io/#/Bilibili-App-API)     - ğŸ¬ [Sora2 æ¥å£](https://api.tikhub.io/#/Sora2-API)     - âš¡ [å¿«æ‰‹ç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/Kuaishou-Web-API)     - âš¡ [å¿«æ‰‹ App æ•°æ®æ¥å£](https://api.tikhub.io/#/Kuaishou-App-API)     - ğŸ¦ [çš®çš®è™¾ App æ•°æ®æ¥å£](https://api.tikhub.io/#/PiPiXia-App-API)     - ğŸ”„ [å¾®åšç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/Weibo-Web-API)     - ğŸ”„ [å¾®åšç½‘é¡µç‰ˆ V2æ•°æ®æ¥å£](https://api.tikhub.io/#/Weibo-Web-V2-API)     - ğŸ”„ [å¾®åšAPPæ•°æ®æ¥å£](https://api.tikhub.io/#/Weibo-App-API)     - ğŸ’¬ [å¾®ä¿¡å…¬ä¼—å·ç½‘é¡µç‰ˆæ•°æ®æ¥å£](https://api.tikhub.io/#/WeChat-Channels-API)     - ğŸ“± [å¾®ä¿¡è§†é¢‘å·æ•°æ®æ¥å£](https://api.tikhub.io/#/WeChat-Channels-API)     - ğŸ“¸ [Instagram Webä»¥åŠAPPæ•°æ®æ¥å£](https://api.tikhub.io/#/Instagram-Web-And-APP-API) - ï¼ˆå·²å¼ƒç”¨å¹¶ä¸”ä¸‹æ¶æ¥å£æ–‡æ¡£ï¼Œè¯·ä½¿ç”¨æ–°ç‰ˆæ¥å£ï¼‰     - ğŸ“¸ [Instagram V1æ•°æ®æ¥å£](https://api.tikhub.io/#/Instagram-V1-API)     - ğŸ“¸ [Instagram V2æ•°æ®æ¥å£](https://api.tikhub.io/#/Instagram-V2-API)     - ğŸ“¹ [YouTube Webæ•°æ®æ¥å£](https://api.tikhub.io/#/YouTube-Web-API)     - ğŸ“¹ [YouTube Web V2æ•°æ®æ¥å£](https://api.tikhub.io/#/YouTube-Web-V2-API)     - ğŸµ [ç½‘æ˜“äº‘éŸ³ä¹Appæ•°æ®æ¥å£](https://api.tikhub.io/#/NetEase-Cloud-Music-API)     - ğŸ¦ [Twitter Webæ•°æ®æ¥å£](https://api.tikhub.io/#/Twitter-Web-API)     - ğŸ§µ [Threads Webæ•°æ®æ¥å£](https://api.tikhub.io/#/Threads-Web-API)     - ğŸ”´ [Reddit Webæ•°æ®æ¥å£](https://api.tikhub.io/#/Reddit-Web-API)     - ğŸ”´ [Reddit APPæ•°æ®æ¥å£](https://api.tikhub.io/#/Reddit-APP-API)     - ğŸ’¼ [LinkedIn Webæ•°æ®æ¥å£](https://api.tikhub.io/#/LinkedIn-Web-API)     - â“ [çŸ¥ä¹Webæ•°æ®æ¥å£](https://api.tikhub.io/#/Zhihu-Web-API)     - ğŸ¤– [éªŒè¯ç ç»•è¿‡æ¥å£](https://api.tikhub.io/#/Captcha-Solver)     - âœ‰ï¸ [ä¸´æ—¶é‚®ç®±æ¥å£](https://api.tikhub.io/#/Temp-Mail-API) - ğŸ“¢ è¯·å°†ä»»ä½•é—®é¢˜æˆ–é”™è¯¯æŠ¥å‘Šç»™[DiscordæœåŠ¡å™¨](https://discord.gg/aMEAS8Xsvz)ã€‚  #### ğŸ‘¤ ç”¨æˆ· - **ğŸ–¥ï¸ å®˜ç½‘/ç”¨æˆ·åå°/ç”¨æˆ·æ”¯ä»˜**: [TikHub User](https://user.tikhub.io/users/signin)  #### ğŸ“¢ æ›´æ–°é€šçŸ¥ - **ğŸ‘‹ æ–°ç”¨æˆ·æ³¨å†Œ**   - è¯·æ³¨å†Œå¹¶**âœ… éªŒè¯é‚®ç®±**åï¼Œæ‰èƒ½ä½¿ç”¨APIåŠè´­ä¹°æœåŠ¡ã€‚ - **ğŸ’° æ”¯ä»˜**     - ğŸ’¸ PayPal æ”¯ä»˜ï¼šæ”¯æŒ Visaã€MasterCardã€American Express ç­‰å›½é™…ä¿¡ç”¨å¡ï¼›ä¸­å›½ç”¨æˆ·å¯ç›´æ¥ä½¿ç”¨**ä»»æ„é“¶è”ä¿¡ç”¨/å‚¨è“„å¡**ã€‚ä»˜æ¬¾æ—¶**æ— éœ€æ³¨å†Œ PayPal**ï¼Œè¯·åœ¨é¡µé¢é€‰æ‹©ã€Œä¿¡ç”¨å¡/å€Ÿè®°å¡ã€æ–¹å¼å®Œæˆæ”¯ä»˜ã€‚     - ğŸª™ Cryptocurrencyæ”¯ä»˜: æ”¯æŒUSDT TRC20 åŠ å¯†è´§å¸æ”¯ä»˜ã€‚     - ğŸ“ å¦‚æœä»¥ä¸Šæ”¯ä»˜æ–¹å¼æ— æ³•æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼Œè¯·è”ç³»æˆ‘ä»¬ã€‚ - **ğŸ æ¨èç **     - æ‚¨å¯ä»¥å°†æ¨èç æ³¨å†Œé“¾æ¥å‘é€ç»™æœ‹å‹ã€‚å½“æ‚¨å’Œæ‚¨çš„æœ‹å‹éƒ½æˆä¸ºä»˜è´¹ç”¨æˆ·åï¼ŒåŒæ–¹å°†å„è·å¾—2ç¾å…ƒçš„ä½™é¢ï¼ˆçº¦2000æ¬¡è¯·æ±‚é‡ï¼‰ã€‚     - ğŸ”‘ æ¨èç æ³¨å†Œé“¾æ¥åœ¨ä¸ªäººä¸»é¡µä¸­æŸ¥çœ‹å’Œç”Ÿæˆ     - â±ï¸ æ¨èç æ³¨å†Œé“¾æ¥æœ‰æ•ˆæœŸä¸º90å¤©     - âœ… ä½¿ç”¨æ¨èç çš„æ—¶å€™è¦ç¡®ä¿æ‚¨çš„è´¦æˆ·å·²éªŒè¯é‚®ç®±å¹¶ä¸”æ˜¯ä»˜è´¹ç”¨æˆ· - **ğŸ”‘ API Keyä½¿ç”¨**     - ğŸ” è¯·åœ¨ç”ŸæˆAPI Keyåç«‹å³ä¿å­˜ï¼Œå› ä¸ºAPI Keyåªä¼šåœ¨åˆ›å»ºåæ˜¾ç¤ºä¸€æ¬¡ã€‚     - ğŸ”¢ æ¯ä½ç”¨æˆ·æœ€å¤šå¯åˆ›å»º20ä¸ªAPI Keyã€‚ - **ğŸ†“ APIå…è´¹è¯•ç”¨**     - æ¯ä¸ªç”¨æˆ·æ³¨å†Œå¹¶ä¸”éªŒè¯é‚®ç®±åï¼Œå¯ä»¥åœ¨ç”¨æˆ·åå°çš„å³ä¸Šè§’ç‚¹å‡»ç­¾åˆ°æŒ‰é’®ï¼Œè·å–å…è´¹è¯•ç”¨é¢åº¦ï¼Œæ¯24å°æ—¶å¯ä»¥ç­¾åˆ°ä¸€æ¬¡ã€‚  ----  #### ğŸ”‘ APIä»¤ç‰Œç®€ä»‹: ##### ğŸ“ æ–¹æ³•ä¸€ï¼šåœ¨è¯·æ±‚å¤´ä¸­ä½¿ç”¨APIä»¤ç‰Œï¼ˆæ¨èï¼‰ - **ğŸ·ï¸ è¯·æ±‚å¤´**: `Authorization` - **ğŸ“‹ æ ¼å¼**: `Bearer your_token` - **ğŸ“„ ç¤ºä¾‹**: `\"Authorization\": \"Bearer your_token\"` - **ğŸ–¥ï¸ Swagger UI**: ç‚¹å‡»é¡µé¢å³ä¸Šè§’çš„`Authorize`æŒ‰é’®æˆ–ç‚¹å‡»è¦è¯·æ±‚çš„æ¥å£æ—çš„ `ğŸ”’` å›¾æ ‡ï¼Œç„¶åç›´æ¥è¾“å…¥APIä»¤ç‰Œï¼Œæ— éœ€`Bearer`å…³é”®å­—ã€‚  ##### ğŸ“ æ–¹æ³•äºŒï¼šåœ¨Cookieä¸­ä½¿ç”¨APIä»¤ç‰Œï¼ˆä¸æ¨èï¼Œä»…åœ¨æ— æ³•ä½¿ç”¨æ–¹æ³•ä¸€æ—¶ä½¿ç”¨ï¼‰ - **ğŸª Cookie**: `Authorization` - **ğŸ“‹ æ ¼å¼**: `Bearer your_token` - **ğŸ“„ ç¤ºä¾‹**: `Authorization=Bearer your_token`  #### ğŸ”‘ è·å–APIä»¤ç‰Œ: 1. ğŸ“ åœ¨TikHubç½‘ç«™æ³¨å†Œå¹¶ç™»å½•è´¦æˆ·ã€‚ 2. ğŸ‘¤ è¿›å…¥ç”¨æˆ·ä¸­å¿ƒï¼Œç‚¹å‡»APIä»¤ç‰Œèœå•ï¼Œåˆ›å»ºAPIä»¤ç‰Œã€‚ 3. ğŸ“‹ å¤åˆ¶å¹¶åœ¨è¯·æ±‚å¤´ä¸­ä½¿ç”¨APIä»¤ç‰Œã€‚ 4. ğŸ”’ ä¿å¯†æ‚¨çš„APIä»¤ç‰Œï¼Œä»…åœ¨è¯·æ±‚å¤´ä¸­ä½¿ç”¨ã€‚  ----  #### ğŸ“ Note - ğŸŒ TikHub API is a multi-social media data analysis platform that provides the following data interface services for developers and is constantly being updated:     - ğŸ“± [Douyin Web API](https://api.tikhub.io/#/Douyin-Web-API)     - ğŸ“± [Douyin App V1 API](https://api.tikhub.io/#/Douyin-App-V1-API) - (This API version is deprecated and has been removed. Please use the new version of the API.)     - ğŸ“± [Douyin App V2 API](https://api.tikhub.io/#/Douyin-App-V2-API) - (This API version is deprecated and has been removed. Please use the new version of the API.)     - ğŸ“± [Douyin App V3 API](https://api.tikhub.io/#/Douyin-App-V3-API)     - ğŸ”¥ [Douyin Search API](https://api.tikhub.io/#/Douyin-Search-API)     - ğŸ”¥ [Douyin Billboard API](https://api.tikhub.io/#/Douyin-Billboard-API)     - â­ [Douyin Xingtu API](https://api.tikhub.io/#/Douyin-Xingtu-API)     - â­ [Douyin Xingtu V2 API](https://api.tikhub.io/#/Douyin-Xingtu-V2-API)     - ğŸµ [TikTok Web API](https://api.tikhub.io/#/TikTok-Web-API)     - ğŸµ [TikTok App V2 API](https://api.tikhub.io/#/TikTok-App-V2-API) - (This API version is deprecated and has been removed. Please use the new version of the API.)     - ğŸµ [TikTok App V3 API](https://api.tikhub.io/#/TikTok-App-V3-API)     - ğŸ‘¨â€ğŸ¨ [TikTok Creator API - E-commerce](https://api.tikhub.io/#/TikTok-Creator-API)     - ğŸµ [TikTok Analytics API - MCN](https://api.tikhub.io/#/TikTok-Analytics-API)     - ğŸµ [TikTok Shop Web API](https://api.tikhub.io/#/TikTok-Shop-Web-API)     - ğŸµ [TikTok Ads API -Ads](https://api.tikhub.io/#/TikTok-Ads-API)     - ğŸ‰ [Xigua App V2 API](https://api.tikhub.io/#/Xigua-App-V2-API)     - ğŸ“• [Xiaohongshu Web API](https://api.tikhub.io/#/Xiaohongshu-Web-API)     - ğŸ“• [Xiaohongshu Web V2 API](https://api.tikhub.io/#/Xiaohongshu-Web-V2-API)     - ğŸ“• [Xiaohongshu App API](https://api.tikhub.io/#/Xiaohongshu-App-API)     - ğŸ‹ [Lemon8 App API](https://api.tikhub.io/#/Lemon8-App-API)     - ğŸ“º [Bilibili Web API](https://api.tikhub.io/#/Bilibili-Web-API)     - ğŸ“º [Bilibili App API](https://api.tikhub.io/#/Bilibili-App-API)     - ğŸ¬ [Sora2 API](https://api.tikhub.io/#/Sora2-API)     - âš¡ [Kuaishou Web API](https://api.tikhub.io/#/Kuaishou-Web-API)     - âš¡ [Kuaishou App API](https://api.tikhub.io/#/Kuaishou-App-API)     - ğŸ¦ [PiPiXia App API](https://api.tikhub.io/#/PiPiXia-App-API)     - ğŸ”„ [Weibo Web API](https://api.tikhub.io/#/Weibo-Web-API)     - ğŸ”„ [Weibo Web V2 API](https://api.tikhub.io/#/Weibo-Web-V2-API)     - ğŸ”„ [Weibo APP API](https://api.tikhub.io/#/Weibo-App-API)     - ğŸ’¬ [WeChat MP Web API](https://api.tikhub.io/#/WeChat-Channels-API)     - ğŸ“± [WeChat Channels API](https://api.tikhub.io/#/WeChat-Channels-API)     - ğŸ“¸ [Instagram Web & APP API](https://api.tikhub.io/#/Instagram-Web-And-APP-API) - (This API version is deprecated and has been removed. Please use the new version of the API.)     - ğŸ“¸ [Instagram V1 API](https://api.tikhub.io/#/Instagram-V1-API)     - ğŸ“¸ [Instagram V2 API](https://api.tikhub.io/#/Instagram-V2-API)     - ğŸ“¹ [YouTube Web API](https://api.tikhub.io/#/YouTube-Web-API)     - ğŸ“¹ [YouTube Web V2 API](https://api.tikhub.io/#/YouTube-Web-V2-API)     - ğŸµ [NetEase Cloud Music App API](https://api.tikhub.io/#/NetEase-Cloud-Music-API)     - ğŸ¦ [Twitter Web API](https://api.tikhub.io/#/Twitter-Web-API)     - ğŸ§µ [Threads Web API](https://api.tikhub.io/#/Threads-Web-API)     - ğŸ”´ [Reddit Web API](https://api.tikhub.io/#/Reddit-Web-API)     - ğŸ”´ [Reddit APP API](https://api.tikhub.io/#/Reddit-APP-API)     - ğŸ’¼ [LinkedIn Web API](https://api.tikhub.io/#/LinkedIn-Web-API)     - â“ [Zhihu Web API](https://api.tikhub.io/#/Zhihu-Web-API)     - ğŸ¤– [Captcha Solver](https://api.tikhub.io/#/Captcha-Solver)     - âœ‰ï¸ [Temp Mail API](https://api.tikhub.io/#/Temp-Mail-API) - ğŸ“¢ Please report any issues or errors to the [Discord server](https://discord.gg/aMEAS8Xsvz).  #### ğŸ‘¤ Users - **ğŸ–¥ï¸ Official Website/User Dashboard**: [TikHub User](https://user.tikhub.io/users/signin)  #### ğŸ“¢ Update Notice - **ğŸ‘‹ New User Registration**     - Please register and **âœ… verify your email** before using the API and purchasing services. - **ğŸ’° Payment**     - ğŸ’¸ PayPal Payment: We accept Visa, MasterCard, American Express, and other major cards. If youâ€™re in China, simply use any **UnionPay credit** or debit card. **No PayPal account is needed**â€”just select the â€œCredit or Debit Cardâ€ option at checkout.     - ğŸª™ Cryptocurrency Payment: Supports USDT TRC20 cryptocurrencies.     - ğŸ“ If the above payment methods do not meet your needs, please contact us. - **ğŸ Referral Code**     - You can share your referral link with friends. Once both you and your friend become paid users, each of you will receive $2 in credits (approximately 2,000 requests).     - ğŸ”‘ The referral code registration link can be viewed and generated on the personal homepage.     - â±ï¸ The referral code registration link is valid for 90 days.     - âœ… When using the referral code, make sure your account has verified the email and is a paid user. - **ğŸ”‘ API Key Usage**     - ğŸ” Please save the API Key immediately after generating it, as the API Key will only be displayed once after creation.     - ğŸ”¢ Each user can create up to 20 API Keys. - **ğŸ†“ API Free Trial**     - After registering and verifying your email, you can click the Check-in button in the upper right corner of the user dashboard to get a free trial balance, you can sign in once every 24 hours.  ----  #### ğŸ”‘ API Token Introduction: ##### ğŸ“ Method 1: Use API Token in the Request Header (Recommended) - **ğŸ·ï¸ Header**: `Authorization` - **ğŸ“‹ Format**: `Bearer your_token` - **ğŸ“„ Example**: `\"Authorization\": \"Bearer your_token\"` - **ğŸ–¥ï¸ Swagger UI**: Click on the `Authorize` button in the upper right corner of the page or click the `ğŸ”’` icon next to the interface you want to request, and then directly enter the API token without the `Bearer` keyword.  ##### ğŸ“ Method 2: Use API Token in the Cookie (Not Recommended, Use Only When Method 1 is Unavailable) - **ğŸª Cookie**: `Authorization` - **ğŸ“‹ Format**: `Bearer your_token` - **ğŸ“„ Example**: `Authorization=Bearer your_token`  #### ğŸ”‘ Get API Token: 1. ğŸ“ Register and log in to your account on the TikHub website. 2. ğŸ‘¤ Go to the user center, click on the API token menu, and create an API token. 3. ğŸ“‹ Copy and use the API token in the request header. 4. ğŸ”’ Keep your API token confidential and use it only in the request header.  ----  #### ğŸ“š API List Index/æ¥å£åˆ—è¡¨ç´¢å¼• - ğŸ‘¤ [TikHub User API | TikHubç”¨æˆ·æ¥å£](https://api.tikhub.io/#/TikHub-User-API) - ğŸ“± [Douyin Web API | æŠ–éŸ³ç½‘é¡µæ¥å£](https://api.tikhub.io/#/Douyin-Web-API) - ğŸ“± [Douyin App V1 API | æŠ–éŸ³App V1æ¥å£](https://api.tikhub.io/#/Douyin-App-V1-API) - ğŸ“± [Douyin App V2 API | æŠ–éŸ³App V2æ¥å£](https://api.tikhub.io/#/Douyin-App-V2-API) - ğŸ“± [Douyin App V3 API | æŠ–éŸ³App V3æ¥å£](https://api.tikhub.io/#/Douyin-App-V3-API) - ğŸ”¥ [Douyin Search API | æŠ–éŸ³æœç´¢æ¥å£](https://api.tikhub.io/#/Douyin-Search-API) - ğŸ”¥ [Douyin Billboard API | æŠ–éŸ³çƒ­ç‚¹æ¦œæ¥å£](https://api.tikhub.io/#/Douyin-Billboard-API) - â­ [Douyin Xingtu API | æŠ–éŸ³æ˜Ÿå›¾æ¥å£](https://api.tikhub.io/#/Douyin-Xingtu-API) - â­ [Douyin Xingtu V2 API | æŠ–éŸ³æ˜Ÿå›¾V2æ¥å£](https://api.tikhub.io/#/Douyin-Xingtu-V2-API) - ğŸµ [TikTok Web API | TikTokç½‘é¡µæ¥å£](https://api.tikhub.io/#/TikTok-Web-API) - ğŸµ [TikTok App V2 API | TikTok App V2æ¥å£](https://api.tikhub.io/#/TikTok-App-V2-API) - ğŸµ [TikTok App V3 API | TikTok App V3æ¥å£](https://api.tikhub.io/#/TikTok-App-V3-API) - ğŸ‘¨â€ğŸ¨ [TikTok Creator API | TikTokåˆ›ä½œè€…æ¥å£](https://api.tikhub.io/#/TikTok-Creator-API) - ğŸµ [TikTok Analytics API | TikTokæ•°æ®åˆ†ææ¥å£](https://api.tikhub.io/#/TikTok-Analytics-API) - ğŸµ [TikTok Ads API | TikTokå¹¿å‘Šåˆ›æ„ä¸­å¿ƒæ¥å£](https://api.tikhub.io/#/TikTok-Ads-API) - ğŸ‰ [Xigua App V2 API | è¥¿ç“œè§†é¢‘App V2æ¥å£](https://api.tikhub.io/#/Xigua-App-V2-API) - ğŸ“• [Xiaohongshu Web API | å°çº¢ä¹¦Webæ¥å£](https://api.tikhub.io/#/Xiaohongshu-Web-API) - ğŸ“• [Xiaohongshu Web V2 API | å°çº¢ä¹¦WebV2æ¥å£](https://api.tikhub.io/#/Xiaohongshu-Web-V2-API) - ğŸ“• [Xiaohongshu App API | å°çº¢ä¹¦Appæ¥å£](https://api.tikhub.io/#/Xiaohongshu-App-API) - ğŸ‹ [Lemon8 App API | Lemon8 Appæ¥å£](https://api.tikhub.io/#/Lemon8-App-API) - ğŸ“º [Bilibili Web API | å“”å“©å“”å“©Webæ¥å£](https://api.tikhub.io/#/Bilibili-Web-API) - ğŸ“º [Bilibili App API | å“”å“©å“”å“©Webæ¥å£](https://api.tikhub.io/#/Bilibili-App-API) - ğŸ¬ [Sora2 API | Sora2 æ¥å£](https://api.tikhub.io/#/Sora2-API) - âš¡ [Kuaishou Web API | å¿«æ‰‹ç½‘é¡µæ¥å£](https://api.tikhub.io/#/Kuaishou-Web-API) - âš¡ [Kuaishou App API | å¿«æ‰‹Appæ¥å£](https://api.tikhub.io/#/Kuaishou-App-API) - ğŸ¦ [PiPiXia App API | çš®çš®è™¾Appæ¥å£](https://api.tikhub.io/#/PiPiXia-App-API) - ğŸ”„ [Weibo Web API | å¾®åšç½‘é¡µæ¥å£](https://api.tikhub.io/#/Weibo-Web-API) - ğŸ”„ [Weibo Web V2 API | å¾®åšç½‘é¡µV2æ¥å£](https://api.tikhub.io/#/Weibo-Web-V2-API) - ğŸ”„ [Weibo APP API | å¾®åšAPPæ¥å£](https://api.tikhub.io/#/Weibo-App-API) - ğŸ’¬ [WeChat MP Web API | å¾®ä¿¡å…¬ä¼—å·Webæ¥å£](https://api.tikhub.io/#/WeChat-Channels-API) - ğŸ“± [WeChat Channels API | å¾®ä¿¡è§†é¢‘å·æ¥å£](https://api.tikhub.io/#/WeChat-Channels-API) - ğŸ“¸ [Instagram Web & APP API | Instagram Webå’ŒAPPæ¥å£](https://api.tikhub.io/#/Instagram-Web-And-APP-API) - ğŸ“¸ [Instagram V1 API | Instagram V1æ¥å£](https://api.tikhub.io/#/Instagram-V1-API) - ğŸ“¸ [Instagram V2 API | Instagram V2æ¥å£](https://api.tikhub.io/#/Instagram-V2-API) - ğŸ“¹ [YouTube Web API | YouTube Webæ¥å£](https://api.tikhub.io/#/YouTube-Web-API) - ğŸ“¹ [YouTube Web V2 API | YouTube Web V2æ¥å£](https://api.tikhub.io/#/YouTube-Web-V2-API) - ğŸµ [NetEase Cloud Music API | ç½‘æ˜“äº‘éŸ³ä¹Appæ¥å£](https://api.tikhub.io/#/NetEase-Cloud-Music-API) - ğŸ¦ [Twitter Web API | Twitter Webæ¥å£](https://api.tikhub.io/#/Twitter-Web-API) - ğŸ§µ [Threads Web API | Threads Webæ¥å£](https://api.tikhub.io/#/Threads-Web-API) - ğŸ”´ [Reddit Web API | Reddit Webæ¥å£](https://api.tikhub.io/#/Reddit-Web-API) - ğŸ”´ [Reddit APPæ•°æ®æ¥å£ | Reddit APP API](https://api.tikhub.io/#/Reddit-APP-API) - ğŸ’¼ [LinkedIn Web API | LinkedIn Webæ¥å£](https://api.tikhub.io/#/LinkedIn-Web-API) - â“ [Zhihu Web API | çŸ¥ä¹Webæ¥å£](https://api.tikhub.io/#/Zhihu-Web-API) - ğŸ¤– [Captcha Solver | å„ç§éªŒè¯ç ç»•è¿‡æ¥å£](https://api.tikhub.io/#/Captcha-Solver) - âœ‰ï¸ [Temp Mail API | ä¸´æ—¶é‚®ç®±æ¥å£](https://api.tikhub.io/#/Temp-Mail-API)   # noqa: E501

    OpenAPI spec version: V5.3.2
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

from __future__ import absolute_import

import re  # noqa: F401

# python 2 and python 3 compatibility library
import six

from swagger_client.api_client import ApiClient


class RedditAPPAPIApi(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    Ref: https://github.com/swagger-api/swagger-codegen
    """

    def __init__(self, api_client=None):
        if api_client is None:
            api_client = ApiClient()
        self.api_client = api_client

    def check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get(self, subreddit_id, **kwargs):  # noqa: E501
        """æ£€æŸ¥ç‰ˆå—æ˜¯å¦é™éŸ³/Check if Subreddit is Muted  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - æ£€æŸ¥æŒ‡å®šRedditç‰ˆå—æ˜¯å¦è¢«å½“å‰ç”¨æˆ·é™éŸ³ ### å‚æ•°: - subreddit_id: ç‰ˆå—ID,æ ¼å¼ä¸º\"t5_\"å¼€å¤´,å¯ä»fetch_subreddit_infoæ¥å£è·å– ### è¿”å›: - é™éŸ³çŠ¶æ€JSONæ•°æ®,åŒ…å«:   - isMuted: æ˜¯å¦é™éŸ³çš„å¸ƒå°”å€¼   - subredditId: ç‰ˆå—ID ### æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - ç‰ˆå—IDå‰ç¼€: t5_ (ä¾‹å¦‚: t5_2qh0u)  # [English] ### Purpose: - Check if a specified Reddit subreddit is muted by the current user ### Parameters: - subreddit_id: Subreddit ID starting with \"t5_\", can be obtained from fetch_subreddit_info endpoint ### Returns: - JSON data of mute status containing:   - isMuted: Boolean value indicating if muted   - subredditId: Subreddit ID ### Note: - **APP API ID format differs from Web API, requires type prefix** - Subreddit ID prefix: t5_ (e.g., t5_2qh0u)  # [ç¤ºä¾‹/Example] subreddit_id=\"t5_2qh0u\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get(subreddit_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_id: ç‰ˆå—ID/Subreddit ID (format: t5_xxxxx) (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get_with_http_info(subreddit_id, **kwargs)  # noqa: E501
        else:
            (data) = self.check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get_with_http_info(subreddit_id, **kwargs)  # noqa: E501
            return data

    def check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get_with_http_info(self, subreddit_id, **kwargs):  # noqa: E501
        """æ£€æŸ¥ç‰ˆå—æ˜¯å¦é™éŸ³/Check if Subreddit is Muted  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - æ£€æŸ¥æŒ‡å®šRedditç‰ˆå—æ˜¯å¦è¢«å½“å‰ç”¨æˆ·é™éŸ³ ### å‚æ•°: - subreddit_id: ç‰ˆå—ID,æ ¼å¼ä¸º\"t5_\"å¼€å¤´,å¯ä»fetch_subreddit_infoæ¥å£è·å– ### è¿”å›: - é™éŸ³çŠ¶æ€JSONæ•°æ®,åŒ…å«:   - isMuted: æ˜¯å¦é™éŸ³çš„å¸ƒå°”å€¼   - subredditId: ç‰ˆå—ID ### æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - ç‰ˆå—IDå‰ç¼€: t5_ (ä¾‹å¦‚: t5_2qh0u)  # [English] ### Purpose: - Check if a specified Reddit subreddit is muted by the current user ### Parameters: - subreddit_id: Subreddit ID starting with \"t5_\", can be obtained from fetch_subreddit_info endpoint ### Returns: - JSON data of mute status containing:   - isMuted: Boolean value indicating if muted   - subredditId: Subreddit ID ### Note: - **APP API ID format differs from Web API, requires type prefix** - Subreddit ID prefix: t5_ (e.g., t5_2qh0u)  # [ç¤ºä¾‹/Example] subreddit_id=\"t5_2qh0u\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get_with_http_info(subreddit_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_id: ç‰ˆå—ID/Subreddit ID (format: t5_xxxxx) (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subreddit_id', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'subreddit_id' is set
        if self.api_client.client_side_validation and ('subreddit_id' not in params or
                                                       params['subreddit_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `subreddit_id` when calling `check_subreddit_muted_api_v1_reddit_app_check_subreddit_muted_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subreddit_id' in params:
            query_params.append(('subreddit_id', params['subreddit_id']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/check_subreddit_muted', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get(self, post_id, cursor, **kwargs):  # noqa: E501
        """è·å–Reddit APPè¯„è®ºå›å¤ï¼ˆäºŒçº§è¯„è®ºï¼‰/Fetch Reddit APP Comment Replies (Sub-comments)  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šè¯„è®ºä¸‹çš„å›å¤ï¼ˆäºŒçº§è¯„è®º/å­è¯„è®ºï¼‰ - å½“è¯„è®ºèŠ‚ç‚¹æœ‰ more.cursor å­—æ®µæ—¶ï¼Œä½¿ç”¨æ­¤æ¥å£è·å–è¯¥è¯„è®ºçš„å­è¯„è®º ### å‚æ•°: - post_id: å¸–å­IDï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX\" - cursor: è¯„è®ºæ¸¸æ ‡ï¼Œä»è¯„è®ºæ•°æ®çš„ more.cursor å­—æ®µè·å–ï¼Œæ ¼å¼å¦‚ \"commenttree:ex:(xxx)\" - sort_type: æ’åºæ–¹å¼ï¼Œæ”¯æŒCONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM ### è¿”å›: - æŒ‡å®šè¯„è®ºä¸‹çš„å›å¤JSONæ•°æ®ï¼ŒåŒ…å«ï¼š   - å­è¯„è®ºåˆ—è¡¨   - æ¯ä¸ªå­è¯„è®ºçš„è¯¦ç»†ä¿¡æ¯ï¼ˆå†…å®¹ã€ä½œè€…ã€ç‚¹èµæ•°ç­‰ï¼‰   - åˆ†é¡µä¿¡æ¯ ### ä½¿ç”¨æ­¥éª¤: 1. å…ˆè°ƒç”¨ fetch_post_comments è·å–å¸–å­çš„ä¸€çº§è¯„è®º 2. åœ¨è¿”å›æ•°æ®ä¸­æ‰¾åˆ°æœ‰å­è¯„è®ºçš„èŠ‚ç‚¹ï¼ˆchildCount > 0ï¼‰ 3. è·å–è¯¥èŠ‚ç‚¹çš„ more.cursor å€¼ 4. ä½¿ç”¨è¯¥ cursor è°ƒç”¨æœ¬æ¥å£è·å–å­è¯„è®º ### æ³¨æ„: - cursor å€¼æ¥è‡ªè¯„è®ºæ•°æ®çš„ more.cursor å­—æ®µ - è·¯å¾„ç¤ºä¾‹: $.data.postInfoById.commentForest.trees[*].more.cursor - cursor æ ¼å¼ç±»ä¼¼: \"commenttree:ex:(RjiJd\"  # [English] ### Purpose: - Fetch replies (sub-comments/second-level comments) under a specified Reddit APP comment - Use this endpoint when a comment node has more.cursor field to get its sub-comments ### Parameters: - post_id: Post ID, format like \"t3_XXXXXX\" - cursor: Comment cursor from the more.cursor field in comment data, format like \"commenttree:ex:(xxx)\" - sort_type: Sort method, supports CONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM ### Returns: - JSON data of replies under the specified comment, containing:   - List of sub-comments   - Detailed information for each sub-comment (content, author, upvotes, etc.)   - Pagination information ### Usage Steps: 1. First call fetch_post_comments to get top-level comments 2. Find comment nodes with sub-comments (childCount > 0) 3. Get the more.cursor value from that node 4. Use that cursor to call this endpoint to fetch sub-comments ### Note: - cursor value comes from the more.cursor field in comment data - Path example: $.data.postInfoById.commentForest.trees[*].more.cursor - cursor format example: \"commenttree:ex:(RjiJd\"  # [ç¤ºä¾‹/Example] post_id=\"t3_1qmup73\" cursor=\"commenttree:ex:(RjiJd\" sort_type=\"CONFIDENCE\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get(post_id, cursor, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_id: å¸–å­ID/Post ID (e.g., t3_1qmup73) (required)
        :param object cursor: è¯„è®ºæ¸¸æ ‡/Comment cursor from more.cursor field (e.g., commenttree:ex:(RjiJd) (required)
        :param object sort_type: æ’åºæ–¹å¼/Sort method: CONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get_with_http_info(post_id, cursor, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get_with_http_info(post_id, cursor, **kwargs)  # noqa: E501
            return data

    def fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get_with_http_info(self, post_id, cursor, **kwargs):  # noqa: E501
        """è·å–Reddit APPè¯„è®ºå›å¤ï¼ˆäºŒçº§è¯„è®ºï¼‰/Fetch Reddit APP Comment Replies (Sub-comments)  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šè¯„è®ºä¸‹çš„å›å¤ï¼ˆäºŒçº§è¯„è®º/å­è¯„è®ºï¼‰ - å½“è¯„è®ºèŠ‚ç‚¹æœ‰ more.cursor å­—æ®µæ—¶ï¼Œä½¿ç”¨æ­¤æ¥å£è·å–è¯¥è¯„è®ºçš„å­è¯„è®º ### å‚æ•°: - post_id: å¸–å­IDï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX\" - cursor: è¯„è®ºæ¸¸æ ‡ï¼Œä»è¯„è®ºæ•°æ®çš„ more.cursor å­—æ®µè·å–ï¼Œæ ¼å¼å¦‚ \"commenttree:ex:(xxx)\" - sort_type: æ’åºæ–¹å¼ï¼Œæ”¯æŒCONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM ### è¿”å›: - æŒ‡å®šè¯„è®ºä¸‹çš„å›å¤JSONæ•°æ®ï¼ŒåŒ…å«ï¼š   - å­è¯„è®ºåˆ—è¡¨   - æ¯ä¸ªå­è¯„è®ºçš„è¯¦ç»†ä¿¡æ¯ï¼ˆå†…å®¹ã€ä½œè€…ã€ç‚¹èµæ•°ç­‰ï¼‰   - åˆ†é¡µä¿¡æ¯ ### ä½¿ç”¨æ­¥éª¤: 1. å…ˆè°ƒç”¨ fetch_post_comments è·å–å¸–å­çš„ä¸€çº§è¯„è®º 2. åœ¨è¿”å›æ•°æ®ä¸­æ‰¾åˆ°æœ‰å­è¯„è®ºçš„èŠ‚ç‚¹ï¼ˆchildCount > 0ï¼‰ 3. è·å–è¯¥èŠ‚ç‚¹çš„ more.cursor å€¼ 4. ä½¿ç”¨è¯¥ cursor è°ƒç”¨æœ¬æ¥å£è·å–å­è¯„è®º ### æ³¨æ„: - cursor å€¼æ¥è‡ªè¯„è®ºæ•°æ®çš„ more.cursor å­—æ®µ - è·¯å¾„ç¤ºä¾‹: $.data.postInfoById.commentForest.trees[*].more.cursor - cursor æ ¼å¼ç±»ä¼¼: \"commenttree:ex:(RjiJd\"  # [English] ### Purpose: - Fetch replies (sub-comments/second-level comments) under a specified Reddit APP comment - Use this endpoint when a comment node has more.cursor field to get its sub-comments ### Parameters: - post_id: Post ID, format like \"t3_XXXXXX\" - cursor: Comment cursor from the more.cursor field in comment data, format like \"commenttree:ex:(xxx)\" - sort_type: Sort method, supports CONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM ### Returns: - JSON data of replies under the specified comment, containing:   - List of sub-comments   - Detailed information for each sub-comment (content, author, upvotes, etc.)   - Pagination information ### Usage Steps: 1. First call fetch_post_comments to get top-level comments 2. Find comment nodes with sub-comments (childCount > 0) 3. Get the more.cursor value from that node 4. Use that cursor to call this endpoint to fetch sub-comments ### Note: - cursor value comes from the more.cursor field in comment data - Path example: $.data.postInfoById.commentForest.trees[*].more.cursor - cursor format example: \"commenttree:ex:(RjiJd\"  # [ç¤ºä¾‹/Example] post_id=\"t3_1qmup73\" cursor=\"commenttree:ex:(RjiJd\" sort_type=\"CONFIDENCE\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get_with_http_info(post_id, cursor, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_id: å¸–å­ID/Post ID (e.g., t3_1qmup73) (required)
        :param object cursor: è¯„è®ºæ¸¸æ ‡/Comment cursor from more.cursor field (e.g., commenttree:ex:(RjiJd) (required)
        :param object sort_type: æ’åºæ–¹å¼/Sort method: CONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['post_id', 'cursor', 'sort_type', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'post_id' is set
        if self.api_client.client_side_validation and ('post_id' not in params or
                                                       params['post_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `post_id` when calling `fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get`")  # noqa: E501
        # verify the required parameter 'cursor' is set
        if self.api_client.client_side_validation and ('cursor' not in params or
                                                       params['cursor'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `cursor` when calling `fetch_comment_replies_api_v1_reddit_app_fetch_comment_replies_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'post_id' in params:
            query_params.append(('post_id', params['post_id']))  # noqa: E501
        if 'cursor' in params:
            query_params.append(('cursor', params['cursor']))  # noqa: E501
        if 'sort_type' in params:
            query_params.append(('sort_type', params['sort_type']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_comment_replies', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get(self, subreddit_id, **kwargs):  # noqa: E501
        """è·å–Reddit APPç¤¾åŒºäº®ç‚¹/Fetch Reddit APP Community Highlights  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç¤¾åŒºçš„ç²¾é€‰äº®ç‚¹å†…å®¹,åŒ…æ‹¬çƒ­é—¨å¸–å­å’Œé‡è¦å…¬å‘Š ### å‚æ•°: - subreddit_id: ç‰ˆå—ID,æ ¼å¼ä¸º\"t5_\"å¼€å¤´,å¯ä»fetch_subreddit_infoæ¥å£è·å– ### è¿”å›: - ç¤¾åŒºäº®ç‚¹JSONæ•°æ®,åŒ…å«:   - ç²¾é€‰å¸–å­åˆ—è¡¨   - ç½®é¡¶å…¬å‘Š   - ç¤¾åŒºé‡è¦åŠ¨æ€   - æ¨èå†…å®¹ ### æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - ç‰ˆå—IDå‰ç¼€: t5_ (ä¾‹å¦‚: t5_2qh0u)  # [English] ### Purpose: - Fetch featured highlight content of a specified Reddit APP community, including popular posts and important announcements ### Parameters: - subreddit_id: Subreddit ID starting with \"t5_\", can be obtained from fetch_subreddit_info endpoint ### Returns: - JSON data of community highlights containing:   - Featured post list   - Pinned announcements   - Important community updates   - Recommended content ### Note: - **APP API ID format differs from Web API, requires type prefix** - Subreddit ID prefix: t5_ (e.g., t5_2qh0u)  # [ç¤ºä¾‹/Example] subreddit_id=\"t5_2qh0u\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get(subreddit_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_id: ç‰ˆå—ID/Subreddit ID (format: t5_xxxxx) (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get_with_http_info(subreddit_id, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get_with_http_info(subreddit_id, **kwargs)  # noqa: E501
            return data

    def fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get_with_http_info(self, subreddit_id, **kwargs):  # noqa: E501
        """è·å–Reddit APPç¤¾åŒºäº®ç‚¹/Fetch Reddit APP Community Highlights  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç¤¾åŒºçš„ç²¾é€‰äº®ç‚¹å†…å®¹,åŒ…æ‹¬çƒ­é—¨å¸–å­å’Œé‡è¦å…¬å‘Š ### å‚æ•°: - subreddit_id: ç‰ˆå—ID,æ ¼å¼ä¸º\"t5_\"å¼€å¤´,å¯ä»fetch_subreddit_infoæ¥å£è·å– ### è¿”å›: - ç¤¾åŒºäº®ç‚¹JSONæ•°æ®,åŒ…å«:   - ç²¾é€‰å¸–å­åˆ—è¡¨   - ç½®é¡¶å…¬å‘Š   - ç¤¾åŒºé‡è¦åŠ¨æ€   - æ¨èå†…å®¹ ### æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - ç‰ˆå—IDå‰ç¼€: t5_ (ä¾‹å¦‚: t5_2qh0u)  # [English] ### Purpose: - Fetch featured highlight content of a specified Reddit APP community, including popular posts and important announcements ### Parameters: - subreddit_id: Subreddit ID starting with \"t5_\", can be obtained from fetch_subreddit_info endpoint ### Returns: - JSON data of community highlights containing:   - Featured post list   - Pinned announcements   - Important community updates   - Recommended content ### Note: - **APP API ID format differs from Web API, requires type prefix** - Subreddit ID prefix: t5_ (e.g., t5_2qh0u)  # [ç¤ºä¾‹/Example] subreddit_id=\"t5_2qh0u\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get_with_http_info(subreddit_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_id: ç‰ˆå—ID/Subreddit ID (format: t5_xxxxx) (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subreddit_id', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'subreddit_id' is set
        if self.api_client.client_side_validation and ('subreddit_id' not in params or
                                                       params['subreddit_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `subreddit_id` when calling `fetch_community_highlights_api_v1_reddit_app_fetch_community_highlights_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subreddit_id' in params:
            query_params.append(('subreddit_id', params['subreddit_id']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_community_highlights', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get(self, query, **kwargs):  # noqa: E501
        """è·å–Reddit APPåŠ¨æ€æœç´¢ç»“æœ/Fetch Reddit APP Dynamic Search Results  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - æ‰§è¡ŒReddit APPåŠ¨æ€æœç´¢,æ”¯æŒæœç´¢å¸–å­ã€ç¤¾åŒºã€è¯„è®ºã€åª’ä½“å’Œç”¨æˆ· ### å‚æ•°: - query: æœç´¢å…³é”®è¯ - search_type: æœç´¢ç±»å‹,å¯é€‰å€¼:   - post: æœç´¢å¸–å­(é»˜è®¤)   - community: æœç´¢ç¤¾åŒº/ç‰ˆå—   - comment: æœç´¢è¯„è®º   - media: æœç´¢åª’ä½“(å›¾ç‰‡/è§†é¢‘/GIF)   - people: æœç´¢ç”¨æˆ· - sort: æ’åºæ–¹å¼(ä»…é€‚ç”¨äºpost/comment/mediaç±»å‹),å¯é€‰å€¼:   - RELEVANCE: ç›¸å…³æ€§   - HOT: çƒ­é—¨   - TOP: æœ€å—æ¬¢è¿   - NEW: æœ€æ–°   - COMMENTS: è¯„è®ºæ•°(ä»…é€‚ç”¨äºpostç±»å‹) - time_range: æ—¶é—´èŒƒå›´(ä»…é€‚ç”¨äºpost/mediaç±»å‹),å¯é€‰å€¼:   - all: æ‰€æœ‰æ—¶é—´   - year: å»å¹´   - month: ä¸Šä¸ªæœˆ   - week: ä¸Šå‘¨   - day: ä»Šå¤©   - hour: è¿‡å»1å°æ—¶ - safe_search: å®‰å…¨æœç´¢è®¾ç½®,\"unset\"æˆ–\"strict\" - allow_nsfw: æ˜¯å¦å…è®¸NSFWå†…å®¹,\"0\"æˆ–\"1\" - after: åˆ†é¡µå‚æ•°,ç”¨äºè·å–ä¸‹ä¸€é¡µç»“æœ ### è¿”å›: - æœç´¢ç»“æœJSONæ•°æ®,åŒ…å«:   - åŒ¹é…çš„ç»“æœåˆ—è¡¨(æ ¹æ®search_typeä¸åŒè¿”å›ä¸åŒç±»å‹çš„æ•°æ®)   - åˆ†é¡µä¿¡æ¯ ### æ³¨æ„: - communityå’Œpeopleç±»å‹ä¸æ”¯æŒsortå’Œtime_rangeå‚æ•° - COMMENTSæ’åºæ–¹å¼ä»…é€‚ç”¨äºpostç±»å‹ - time_rangeå‚æ•°ä»…é€‚ç”¨äºpostå’Œmediaç±»å‹  # [English] ### Purpose: - Perform Reddit APP dynamic search, supporting posts, communities, comments, media, and users ### Parameters: - query: Search keyword - search_type: Search type, options:   - post: Search posts (default)   - community: Search communities/subreddits   - comment: Search comments   - media: Search media (images/videos/GIFs)   - people: Search users - sort: Sort method (only for post/comment/media types), options:   - RELEVANCE: By relevance   - HOT: Hot/trending   - TOP: Most popular   - NEW: Newest   - COMMENTS: By comment count (only for post type) - time_range: Time range (only for post/media types), options:   - all: All time   - year: Past year   - month: Past month   - week: Past week   - day: Today   - hour: Past hour - safe_search: Safe search setting, \"unset\" or \"strict\" - allow_nsfw: Allow NSFW content, \"0\" or \"1\" - after: Pagination parameter for fetching next page ### Returns: - JSON data of search results containing:   - List of matching results (different data types based on search_type)   - Pagination information ### Notes: - community and people types do not support sort and time_range parameters - COMMENTS sort option only applies to post type - time_range parameter only applies to post and media types  # [ç¤ºä¾‹/Example] query=\"python programming\" search_type=\"post\" sort=\"RELEVANCE\" time_range=\"all\" safe_search=\"unset\" allow_nsfw=\"0\" after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get(query, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object query: æœç´¢å…³é”®è¯/Search query (required)
        :param object search_type: æœç´¢ç±»å‹/Search type: post(å¸–å­), community(ç¤¾åŒº), comment(è¯„è®º), media(åª’ä½“), people(ç”¨æˆ·)
        :param object sort: æ’åºæ–¹å¼(ä»…é€‚ç”¨äºpost/comment/media)/Sort method (only for post/comment/media): RELEVANCE(ç›¸å…³æ€§), HOT(çƒ­é—¨), TOP(æœ€å—æ¬¢è¿), NEW(æœ€æ–°), COMMENTS(è¯„è®ºæ•°,ä»…post)
        :param object time_range: æ—¶é—´èŒƒå›´(ä»…é€‚ç”¨äºpost/media)/Time range (only for post/media): all(æ‰€æœ‰æ—¶é—´), year(å»å¹´), month(ä¸Šæœˆ), week(ä¸Šå‘¨), day(ä»Šå¤©), hour(è¿‡å»1å°æ—¶)
        :param object safe_search: å®‰å…¨æœç´¢è®¾ç½®/Safe search setting: unset, strict
        :param object allow_nsfw: æ˜¯å¦å…è®¸NSFWå†…å®¹/Allow NSFW content: 0, 1
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get_with_http_info(query, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get_with_http_info(query, **kwargs)  # noqa: E501
            return data

    def fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get_with_http_info(self, query, **kwargs):  # noqa: E501
        """è·å–Reddit APPåŠ¨æ€æœç´¢ç»“æœ/Fetch Reddit APP Dynamic Search Results  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - æ‰§è¡ŒReddit APPåŠ¨æ€æœç´¢,æ”¯æŒæœç´¢å¸–å­ã€ç¤¾åŒºã€è¯„è®ºã€åª’ä½“å’Œç”¨æˆ· ### å‚æ•°: - query: æœç´¢å…³é”®è¯ - search_type: æœç´¢ç±»å‹,å¯é€‰å€¼:   - post: æœç´¢å¸–å­(é»˜è®¤)   - community: æœç´¢ç¤¾åŒº/ç‰ˆå—   - comment: æœç´¢è¯„è®º   - media: æœç´¢åª’ä½“(å›¾ç‰‡/è§†é¢‘/GIF)   - people: æœç´¢ç”¨æˆ· - sort: æ’åºæ–¹å¼(ä»…é€‚ç”¨äºpost/comment/mediaç±»å‹),å¯é€‰å€¼:   - RELEVANCE: ç›¸å…³æ€§   - HOT: çƒ­é—¨   - TOP: æœ€å—æ¬¢è¿   - NEW: æœ€æ–°   - COMMENTS: è¯„è®ºæ•°(ä»…é€‚ç”¨äºpostç±»å‹) - time_range: æ—¶é—´èŒƒå›´(ä»…é€‚ç”¨äºpost/mediaç±»å‹),å¯é€‰å€¼:   - all: æ‰€æœ‰æ—¶é—´   - year: å»å¹´   - month: ä¸Šä¸ªæœˆ   - week: ä¸Šå‘¨   - day: ä»Šå¤©   - hour: è¿‡å»1å°æ—¶ - safe_search: å®‰å…¨æœç´¢è®¾ç½®,\"unset\"æˆ–\"strict\" - allow_nsfw: æ˜¯å¦å…è®¸NSFWå†…å®¹,\"0\"æˆ–\"1\" - after: åˆ†é¡µå‚æ•°,ç”¨äºè·å–ä¸‹ä¸€é¡µç»“æœ ### è¿”å›: - æœç´¢ç»“æœJSONæ•°æ®,åŒ…å«:   - åŒ¹é…çš„ç»“æœåˆ—è¡¨(æ ¹æ®search_typeä¸åŒè¿”å›ä¸åŒç±»å‹çš„æ•°æ®)   - åˆ†é¡µä¿¡æ¯ ### æ³¨æ„: - communityå’Œpeopleç±»å‹ä¸æ”¯æŒsortå’Œtime_rangeå‚æ•° - COMMENTSæ’åºæ–¹å¼ä»…é€‚ç”¨äºpostç±»å‹ - time_rangeå‚æ•°ä»…é€‚ç”¨äºpostå’Œmediaç±»å‹  # [English] ### Purpose: - Perform Reddit APP dynamic search, supporting posts, communities, comments, media, and users ### Parameters: - query: Search keyword - search_type: Search type, options:   - post: Search posts (default)   - community: Search communities/subreddits   - comment: Search comments   - media: Search media (images/videos/GIFs)   - people: Search users - sort: Sort method (only for post/comment/media types), options:   - RELEVANCE: By relevance   - HOT: Hot/trending   - TOP: Most popular   - NEW: Newest   - COMMENTS: By comment count (only for post type) - time_range: Time range (only for post/media types), options:   - all: All time   - year: Past year   - month: Past month   - week: Past week   - day: Today   - hour: Past hour - safe_search: Safe search setting, \"unset\" or \"strict\" - allow_nsfw: Allow NSFW content, \"0\" or \"1\" - after: Pagination parameter for fetching next page ### Returns: - JSON data of search results containing:   - List of matching results (different data types based on search_type)   - Pagination information ### Notes: - community and people types do not support sort and time_range parameters - COMMENTS sort option only applies to post type - time_range parameter only applies to post and media types  # [ç¤ºä¾‹/Example] query=\"python programming\" search_type=\"post\" sort=\"RELEVANCE\" time_range=\"all\" safe_search=\"unset\" allow_nsfw=\"0\" after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get_with_http_info(query, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object query: æœç´¢å…³é”®è¯/Search query (required)
        :param object search_type: æœç´¢ç±»å‹/Search type: post(å¸–å­), community(ç¤¾åŒº), comment(è¯„è®º), media(åª’ä½“), people(ç”¨æˆ·)
        :param object sort: æ’åºæ–¹å¼(ä»…é€‚ç”¨äºpost/comment/media)/Sort method (only for post/comment/media): RELEVANCE(ç›¸å…³æ€§), HOT(çƒ­é—¨), TOP(æœ€å—æ¬¢è¿), NEW(æœ€æ–°), COMMENTS(è¯„è®ºæ•°,ä»…post)
        :param object time_range: æ—¶é—´èŒƒå›´(ä»…é€‚ç”¨äºpost/media)/Time range (only for post/media): all(æ‰€æœ‰æ—¶é—´), year(å»å¹´), month(ä¸Šæœˆ), week(ä¸Šå‘¨), day(ä»Šå¤©), hour(è¿‡å»1å°æ—¶)
        :param object safe_search: å®‰å…¨æœç´¢è®¾ç½®/Safe search setting: unset, strict
        :param object allow_nsfw: æ˜¯å¦å…è®¸NSFWå†…å®¹/Allow NSFW content: 0, 1
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['query', 'search_type', 'sort', 'time_range', 'safe_search', 'allow_nsfw', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'query' is set
        if self.api_client.client_side_validation and ('query' not in params or
                                                       params['query'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `query` when calling `fetch_dynamic_search_api_v1_reddit_app_fetch_dynamic_search_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'query' in params:
            query_params.append(('query', params['query']))  # noqa: E501
        if 'search_type' in params:
            query_params.append(('search_type', params['search_type']))  # noqa: E501
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'time_range' in params:
            query_params.append(('time_range', params['time_range']))  # noqa: E501
        if 'safe_search' in params:
            query_params.append(('safe_search', params['safe_search']))  # noqa: E501
        if 'allow_nsfw' in params:
            query_params.append(('allow_nsfw', params['allow_nsfw']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_dynamic_search', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_games_feed_api_v1_reddit_app_fetch_games_feed_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPæ¸¸æˆæ¨èå†…å®¹/Fetch Reddit APP Games Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæ¸¸æˆç›¸å…³çš„æ¨èå†…å®¹,å±•ç¤ºæ¸¸æˆç¤¾åŒºçš„çƒ­é—¨å¸–å­ ### å‚æ•°: - sort: æ’åºæ–¹å¼,å¯é€‰: NEW(æœ€æ–°), HOT(çƒ­é—¨), TOP(é¡¶çº§), RISING(ä¸Šå‡ä¸­) - time: æ—¶é—´èŒƒå›´,å¯é€‰: ALL(å…¨éƒ¨æ—¶é—´), HOUR(ä¸€å°æ—¶), DAY(ä¸€å¤©), WEEK(ä¸€å‘¨), MONTH(ä¸€ä¸ªæœˆ), YEAR(ä¸€å¹´) - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - æ¸¸æˆæ¨èå†…å®¹JSONæ•°æ®,åŒ…å«:   - æ¸¸æˆç›¸å…³å¸–å­åˆ—è¡¨   - æ¸¸æˆç¤¾åŒºè®¨è®º   - æ¸¸æˆæ–°é—»å’Œæ›´æ–°  # [English] ### Purpose: - Fetch gaming-related recommended content on Reddit APP, displaying popular posts from gaming communities ### Parameters: - sort: Sort method, options: NEW, HOT, TOP, RISING - time: Time range, options: ALL, HOUR, DAY, WEEK, MONTH, YEAR - after: Pagination parameter for fetching next page ### Returns: - JSON data of games feed containing:   - List of gaming-related posts   - Gaming community discussions   - Game news and updates  # [ç¤ºä¾‹/Example] sort=\"HOT\" time=\"WEEK\" after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_games_feed_api_v1_reddit_app_fetch_games_feed_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object sort: æ’åºæ–¹å¼/Sort method: NEW, HOT, TOP, RISING
        :param object time: æ—¶é—´èŒƒå›´/Time range: ALL, HOUR, DAY, WEEK, MONTH, YEAR
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_games_feed_api_v1_reddit_app_fetch_games_feed_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_games_feed_api_v1_reddit_app_fetch_games_feed_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_games_feed_api_v1_reddit_app_fetch_games_feed_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPæ¸¸æˆæ¨èå†…å®¹/Fetch Reddit APP Games Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæ¸¸æˆç›¸å…³çš„æ¨èå†…å®¹,å±•ç¤ºæ¸¸æˆç¤¾åŒºçš„çƒ­é—¨å¸–å­ ### å‚æ•°: - sort: æ’åºæ–¹å¼,å¯é€‰: NEW(æœ€æ–°), HOT(çƒ­é—¨), TOP(é¡¶çº§), RISING(ä¸Šå‡ä¸­) - time: æ—¶é—´èŒƒå›´,å¯é€‰: ALL(å…¨éƒ¨æ—¶é—´), HOUR(ä¸€å°æ—¶), DAY(ä¸€å¤©), WEEK(ä¸€å‘¨), MONTH(ä¸€ä¸ªæœˆ), YEAR(ä¸€å¹´) - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - æ¸¸æˆæ¨èå†…å®¹JSONæ•°æ®,åŒ…å«:   - æ¸¸æˆç›¸å…³å¸–å­åˆ—è¡¨   - æ¸¸æˆç¤¾åŒºè®¨è®º   - æ¸¸æˆæ–°é—»å’Œæ›´æ–°  # [English] ### Purpose: - Fetch gaming-related recommended content on Reddit APP, displaying popular posts from gaming communities ### Parameters: - sort: Sort method, options: NEW, HOT, TOP, RISING - time: Time range, options: ALL, HOUR, DAY, WEEK, MONTH, YEAR - after: Pagination parameter for fetching next page ### Returns: - JSON data of games feed containing:   - List of gaming-related posts   - Gaming community discussions   - Game news and updates  # [ç¤ºä¾‹/Example] sort=\"HOT\" time=\"WEEK\" after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_games_feed_api_v1_reddit_app_fetch_games_feed_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object sort: æ’åºæ–¹å¼/Sort method: NEW, HOT, TOP, RISING
        :param object time: æ—¶é—´èŒƒå›´/Time range: ALL, HOUR, DAY, WEEK, MONTH, YEAR
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['sort', 'time', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_games_feed_api_v1_reddit_app_fetch_games_feed_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'time' in params:
            query_params.append(('time', params['time']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_games_feed', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_home_feed_api_v1_reddit_app_fetch_home_feed_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPé¦–é¡µæ¨èå†…å®¹/Fetch Reddit APP Home Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPé¦–é¡µæ¨èå†…å®¹ ### å‚æ•°: - sort: æ’åºæ–¹å¼ï¼Œæ”¯æŒHOT, NEW, TOP, BEST, CONTROVERSIAL - filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨ï¼Œç”¨äºæ’é™¤å·²è·å–çš„å¸–å­ï¼Œé¿å…é‡å¤è·å– - after: åˆ†é¡µå‚æ•°ï¼Œè·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - Reddit APPé¦–é¡µæ¨èå†…å®¹çš„JSONæ•°æ®  # [English] ### Purpose: - Fetch Reddit APP home feed content ### Parameters: - sort: Sort method, supports HOT, NEW, TOP, BEST, CONTROVERSIAL - filter_posts: List of post IDs to filter out, used to exclude already fetched posts - after: Pagination parameter for fetching the next page ### Returns: - JSON data of Reddit APP home feed content  # [ç¤ºä¾‹/Example] sort=\"BEST\"  filter_posts=[\"t3_1ojjquz\",\"t3_1ohepm2\",\"t3_1ojxzzz\",\"t3_1ojnvca\",\"t3_1oj9dcb\",\"t3_1ojxubp\",\"t3_1oj5x2b\"]  after=\"dDNfMW9qNXgyYg==\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_home_feed_api_v1_reddit_app_fetch_home_feed_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object sort: æ’åºæ–¹å¼/Sort method: HOT, NEW, TOP, BEST, CONTROVERSIAL
        :param object filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨/Filter out specified post IDs
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter for fetching next page
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_home_feed_api_v1_reddit_app_fetch_home_feed_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_home_feed_api_v1_reddit_app_fetch_home_feed_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_home_feed_api_v1_reddit_app_fetch_home_feed_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPé¦–é¡µæ¨èå†…å®¹/Fetch Reddit APP Home Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPé¦–é¡µæ¨èå†…å®¹ ### å‚æ•°: - sort: æ’åºæ–¹å¼ï¼Œæ”¯æŒHOT, NEW, TOP, BEST, CONTROVERSIAL - filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨ï¼Œç”¨äºæ’é™¤å·²è·å–çš„å¸–å­ï¼Œé¿å…é‡å¤è·å– - after: åˆ†é¡µå‚æ•°ï¼Œè·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - Reddit APPé¦–é¡µæ¨èå†…å®¹çš„JSONæ•°æ®  # [English] ### Purpose: - Fetch Reddit APP home feed content ### Parameters: - sort: Sort method, supports HOT, NEW, TOP, BEST, CONTROVERSIAL - filter_posts: List of post IDs to filter out, used to exclude already fetched posts - after: Pagination parameter for fetching the next page ### Returns: - JSON data of Reddit APP home feed content  # [ç¤ºä¾‹/Example] sort=\"BEST\"  filter_posts=[\"t3_1ojjquz\",\"t3_1ohepm2\",\"t3_1ojxzzz\",\"t3_1ojnvca\",\"t3_1oj9dcb\",\"t3_1ojxubp\",\"t3_1oj5x2b\"]  after=\"dDNfMW9qNXgyYg==\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_home_feed_api_v1_reddit_app_fetch_home_feed_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object sort: æ’åºæ–¹å¼/Sort method: HOT, NEW, TOP, BEST, CONTROVERSIAL
        :param object filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨/Filter out specified post IDs
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter for fetching next page
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['sort', 'filter_posts', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_home_feed_api_v1_reddit_app_fetch_home_feed_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'filter_posts' in params:
            query_params.append(('filter_posts', params['filter_posts']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_home_feed', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_news_feed_api_v1_reddit_app_fetch_news_feed_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPèµ„è®¯æ¨èå†…å®¹/Fetch Reddit APP News Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæ–°é—»èµ„è®¯æ¨èå†…å®¹,å±•ç¤ºæœ€æ–°çš„æ–°é—»å’Œæ—¶äº‹è®¨è®º ### å‚æ•°: - subtopic_ids: å­è¯é¢˜IDåˆ—è¡¨,é»˜è®¤[\"all\"]è¡¨ç¤ºæ‰€æœ‰æ–°é—»ç±»åˆ« - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - æ–°é—»æ¨èå†…å®¹JSONæ•°æ®,åŒ…å«:   - æ–°é—»å¸–å­åˆ—è¡¨   - æ—¶äº‹è®¨è®º   - çƒ­ç‚¹è¯é¢˜   - æ–°é—»æ¥æºå’Œé“¾æ¥  # [English] ### Purpose: - Fetch news-related recommended content on Reddit APP, displaying latest news and current affairs discussions ### Parameters: - subtopic_ids: List of subtopic IDs, default [\"all\"] means all news categories - after: Pagination parameter for fetching next page ### Returns: - JSON data of news feed containing:   - List of news posts   - Current affairs discussions   - Trending topics   - News sources and links  # [ç¤ºä¾‹/Example] subtopic_ids=[\"all\"] after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_news_feed_api_v1_reddit_app_fetch_news_feed_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subtopic_ids: å­è¯é¢˜IDåˆ—è¡¨/Subtopic IDs list
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_news_feed_api_v1_reddit_app_fetch_news_feed_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_news_feed_api_v1_reddit_app_fetch_news_feed_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_news_feed_api_v1_reddit_app_fetch_news_feed_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPèµ„è®¯æ¨èå†…å®¹/Fetch Reddit APP News Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæ–°é—»èµ„è®¯æ¨èå†…å®¹,å±•ç¤ºæœ€æ–°çš„æ–°é—»å’Œæ—¶äº‹è®¨è®º ### å‚æ•°: - subtopic_ids: å­è¯é¢˜IDåˆ—è¡¨,é»˜è®¤[\"all\"]è¡¨ç¤ºæ‰€æœ‰æ–°é—»ç±»åˆ« - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - æ–°é—»æ¨èå†…å®¹JSONæ•°æ®,åŒ…å«:   - æ–°é—»å¸–å­åˆ—è¡¨   - æ—¶äº‹è®¨è®º   - çƒ­ç‚¹è¯é¢˜   - æ–°é—»æ¥æºå’Œé“¾æ¥  # [English] ### Purpose: - Fetch news-related recommended content on Reddit APP, displaying latest news and current affairs discussions ### Parameters: - subtopic_ids: List of subtopic IDs, default [\"all\"] means all news categories - after: Pagination parameter for fetching next page ### Returns: - JSON data of news feed containing:   - List of news posts   - Current affairs discussions   - Trending topics   - News sources and links  # [ç¤ºä¾‹/Example] subtopic_ids=[\"all\"] after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_news_feed_api_v1_reddit_app_fetch_news_feed_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subtopic_ids: å­è¯é¢˜IDåˆ—è¡¨/Subtopic IDs list
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subtopic_ids', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_news_feed_api_v1_reddit_app_fetch_news_feed_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subtopic_ids' in params:
            query_params.append(('subtopic_ids', params['subtopic_ids']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_news_feed', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_popular_feed_api_v1_reddit_app_fetch_popular_feed_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPæµè¡Œæ¨èå†…å®¹/Fetch Reddit APP Popular Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæµè¡Œ/çƒ­é—¨æ¨èå†…å®¹,å±•ç¤ºå…¨ç«™æœ€å—æ¬¢è¿çš„å¸–å­ ### å‚æ•°: - sort: æ’åºæ–¹å¼,å¯é€‰: BEST(æœ€ä½³), HOT(çƒ­é—¨), NEW(æœ€æ–°), TOP(é¡¶çº§), CONTROVERSIAL(æœ‰äº‰è®®), RISING(ä¸Šå‡ä¸­) - time: æ—¶é—´èŒƒå›´,å¯é€‰: ALL(å…¨éƒ¨æ—¶é—´), HOUR(ä¸€å°æ—¶), DAY(ä¸€å¤©), WEEK(ä¸€å‘¨), MONTH(ä¸€ä¸ªæœˆ), YEAR(ä¸€å¹´) - filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨,ç”¨äºé¿å…é‡å¤è·å– - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - æµè¡Œæ¨èå†…å®¹JSONæ•°æ®,åŒ…å«:   - çƒ­é—¨å¸–å­åˆ—è¡¨   - å¸–å­è¯¦ç»†ä¿¡æ¯(æ ‡é¢˜ã€å†…å®¹ã€ç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰)   - åˆ†é¡µä¿¡æ¯(afterå‚æ•°ç”¨äºä¸‹ä¸€é¡µ)  # [English] ### Purpose: - Fetch popular/trending recommended content on Reddit APP, displaying the most popular posts site-wide ### Parameters: - sort: Sort method, options: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING - time: Time range, options: ALL, HOUR, DAY, WEEK, MONTH, YEAR - filter_posts: List of post IDs to filter out, used to avoid duplicate fetches - after: Pagination parameter for fetching next page ### Returns: - JSON data of popular feed containing:   - List of trending posts   - Detailed post information (title, content, upvotes, comments, etc.)   - Pagination information (after parameter for next page)  # [ç¤ºä¾‹/Example] sort=\"HOT\" time=\"DAY\" filter_posts=[] after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_popular_feed_api_v1_reddit_app_fetch_popular_feed_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object sort: æ’åºæ–¹å¼/Sort method: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING
        :param object time: æ—¶é—´èŒƒå›´/Time range: ALL, HOUR, DAY, WEEK, MONTH, YEAR
        :param object filter_posts: è¿‡æ»¤å¸–å­IDåˆ—è¡¨/Filter post IDs
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_popular_feed_api_v1_reddit_app_fetch_popular_feed_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_popular_feed_api_v1_reddit_app_fetch_popular_feed_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_popular_feed_api_v1_reddit_app_fetch_popular_feed_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPæµè¡Œæ¨èå†…å®¹/Fetch Reddit APP Popular Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæµè¡Œ/çƒ­é—¨æ¨èå†…å®¹,å±•ç¤ºå…¨ç«™æœ€å—æ¬¢è¿çš„å¸–å­ ### å‚æ•°: - sort: æ’åºæ–¹å¼,å¯é€‰: BEST(æœ€ä½³), HOT(çƒ­é—¨), NEW(æœ€æ–°), TOP(é¡¶çº§), CONTROVERSIAL(æœ‰äº‰è®®), RISING(ä¸Šå‡ä¸­) - time: æ—¶é—´èŒƒå›´,å¯é€‰: ALL(å…¨éƒ¨æ—¶é—´), HOUR(ä¸€å°æ—¶), DAY(ä¸€å¤©), WEEK(ä¸€å‘¨), MONTH(ä¸€ä¸ªæœˆ), YEAR(ä¸€å¹´) - filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨,ç”¨äºé¿å…é‡å¤è·å– - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - æµè¡Œæ¨èå†…å®¹JSONæ•°æ®,åŒ…å«:   - çƒ­é—¨å¸–å­åˆ—è¡¨   - å¸–å­è¯¦ç»†ä¿¡æ¯(æ ‡é¢˜ã€å†…å®¹ã€ç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰)   - åˆ†é¡µä¿¡æ¯(afterå‚æ•°ç”¨äºä¸‹ä¸€é¡µ)  # [English] ### Purpose: - Fetch popular/trending recommended content on Reddit APP, displaying the most popular posts site-wide ### Parameters: - sort: Sort method, options: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING - time: Time range, options: ALL, HOUR, DAY, WEEK, MONTH, YEAR - filter_posts: List of post IDs to filter out, used to avoid duplicate fetches - after: Pagination parameter for fetching next page ### Returns: - JSON data of popular feed containing:   - List of trending posts   - Detailed post information (title, content, upvotes, comments, etc.)   - Pagination information (after parameter for next page)  # [ç¤ºä¾‹/Example] sort=\"HOT\" time=\"DAY\" filter_posts=[] after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_popular_feed_api_v1_reddit_app_fetch_popular_feed_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object sort: æ’åºæ–¹å¼/Sort method: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING
        :param object time: æ—¶é—´èŒƒå›´/Time range: ALL, HOUR, DAY, WEEK, MONTH, YEAR
        :param object filter_posts: è¿‡æ»¤å¸–å­IDåˆ—è¡¨/Filter post IDs
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['sort', 'time', 'filter_posts', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_popular_feed_api_v1_reddit_app_fetch_popular_feed_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'time' in params:
            query_params.append(('time', params['time']))  # noqa: E501
        if 'filter_posts' in params:
            query_params.append(('filter_posts', params['filter_posts']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_popular_feed', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get(self, post_id, **kwargs):  # noqa: E501
        """è·å–Reddit APPå¸–å­è¯„è®º/Fetch Reddit APP Post Comments  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šå¸–å­ä¸‹çš„è¯„è®º ### å‚æ•°: - post_id: å¸–å­IDï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX\" - sort_type: æ’åºæ–¹å¼ï¼Œæ”¯æŒCONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM - after: åˆ†é¡µå‚æ•°ï¼Œè·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ï¼Œåœ¨commentForesté‡Œçš„æœ€åä¸€ä¸ªè¯„è®ºèŠ‚ç‚¹ä¸­å¯ä»¥æ‰¾åˆ°ï¼Œä¾‹å¦‚$.data.postInfoById.commentForest.trees[-1].more.cursor ### è¿”å›: - æŒ‡å®šå¸–å­ä¸‹çš„è¯„è®ºJSONæ•°æ® ### æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnvca)  # [English] ### Purpose: - Fetch comments under a specified Reddit APP post ### Parameters: - post_id: Post ID, format like \"t3_XXXXXX\" - sort_type: Sort method, supports HOT, NEW, TOP, BEST, CONTROVERSIAL - after: Pagination parameter for fetching the next page, can be found in the last comment node in commentForest, e.g., $.data.postInfoById.commentForest.trees[-1].more.cursor ### Returns: - JSON data of comments under the specified post ### Note: - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnvca)  # [ç¤ºä¾‹/Example] post_id=\"t3_1ojnvca\"  sort=\"CONFIDENCE\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get(post_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_id: å¸–å­ID/Post ID (required)
        :param object sort_type: æ’åºæ–¹å¼/Sort method: CONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter for fetching next page
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get_with_http_info(post_id, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get_with_http_info(post_id, **kwargs)  # noqa: E501
            return data

    def fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get_with_http_info(self, post_id, **kwargs):  # noqa: E501
        """è·å–Reddit APPå¸–å­è¯„è®º/Fetch Reddit APP Post Comments  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šå¸–å­ä¸‹çš„è¯„è®º ### å‚æ•°: - post_id: å¸–å­IDï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX\" - sort_type: æ’åºæ–¹å¼ï¼Œæ”¯æŒCONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM - after: åˆ†é¡µå‚æ•°ï¼Œè·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ï¼Œåœ¨commentForesté‡Œçš„æœ€åä¸€ä¸ªè¯„è®ºèŠ‚ç‚¹ä¸­å¯ä»¥æ‰¾åˆ°ï¼Œä¾‹å¦‚$.data.postInfoById.commentForest.trees[-1].more.cursor ### è¿”å›: - æŒ‡å®šå¸–å­ä¸‹çš„è¯„è®ºJSONæ•°æ® ### æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnvca)  # [English] ### Purpose: - Fetch comments under a specified Reddit APP post ### Parameters: - post_id: Post ID, format like \"t3_XXXXXX\" - sort_type: Sort method, supports HOT, NEW, TOP, BEST, CONTROVERSIAL - after: Pagination parameter for fetching the next page, can be found in the last comment node in commentForest, e.g., $.data.postInfoById.commentForest.trees[-1].more.cursor ### Returns: - JSON data of comments under the specified post ### Note: - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnvca)  # [ç¤ºä¾‹/Example] post_id=\"t3_1ojnvca\"  sort=\"CONFIDENCE\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get_with_http_info(post_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_id: å¸–å­ID/Post ID (required)
        :param object sort_type: æ’åºæ–¹å¼/Sort method: CONFIDENCE, NEW, TOP, HOT, CONTROVERSIAL, OLD, RANDOM
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter for fetching next page
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['post_id', 'sort_type', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'post_id' is set
        if self.api_client.client_side_validation and ('post_id' not in params or
                                                       params['post_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `post_id` when calling `fetch_post_comments_api_v1_reddit_app_fetch_post_comments_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'post_id' in params:
            query_params.append(('post_id', params['post_id']))  # noqa: E501
        if 'sort_type' in params:
            query_params.append(('sort_type', params['sort_type']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_post_comments', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_post_details_api_v1_reddit_app_fetch_post_details_get(self, post_id, **kwargs):  # noqa: E501
        """è·å–å•ä¸ªRedditå¸–å­è¯¦æƒ…/Fetch Single Reddit Post Details  # noqa: E501

        # [ä¸­æ–‡] ## ç”¨é€”: - æ ¹æ®å¸–å­IDè·å–å•ä¸ªå¸–å­è¯¦æƒ… - å¯é€‰æ‹©æ€§åŒ…å«ç‰¹å®šè¯„è®ºçš„ä¸Šä¸‹æ–‡  ## å‚æ•°: - post_id: å¸–å­IDï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX\" - include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºIDï¼Œé»˜è®¤False - comment_id: è¯„è®ºIDï¼ˆå½“include_comment_idä¸ºTrueæ—¶ä½¿ç”¨ï¼‰ï¼Œæ ¼å¼å¦‚ \"t1_XXXXXX\"  ## è¿”å›: - åŒ…å«å¸–å­è¯¦ç»†ä¿¡æ¯çš„æ•°æ®ï¼ŒåŒ…æ‹¬:   - å¸–å­å†…å®¹ã€æ ‡é¢˜ã€ä½œè€…   - ç»Ÿè®¡æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰   - ç‰ˆå—ä¿¡æ¯   - å¥–åŠ±ä¿¡æ¯   - åª’ä½“èµ„æº   - æ¨èåŸå› ç­‰  ## æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnh50) - è¯„è®ºIDå‰ç¼€: t1_ (ä¾‹å¦‚: t1_abcd123)  ---  # [English] ## Purpose: - Fetch single post details by post ID - Optionally include context for specific comments  ## Parameters: - post_id: Post ID, format like \"t3_XXXXXX\" - include_comment_id: Whether to include specific comment ID, default False - comment_id: Comment ID (used when include_comment_id is True), format like \"t1_XXXXXX\"  ## Returns: - Data containing detailed post information including:   - Post content, title, author   - Statistics (upvotes, comment count, etc.)   - Subreddit information   - Award information   - Media resources   - Recommendation reasons, etc.  ## Note: - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnh50) - Comment ID prefix: t1_ (e.g., t1_abcd123)  # [ç¤ºä¾‹/Example] post_id=\"t3_1ojnh50\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_details_api_v1_reddit_app_fetch_post_details_get(post_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_id: å¸–å­ID/Post ID (e.g., t3_1ojnh50) (required)
        :param object include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºID/Include specific comment ID
        :param object comment_id: è¯„è®ºID/Comment ID (when include_comment_id is True)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_post_details_api_v1_reddit_app_fetch_post_details_get_with_http_info(post_id, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_post_details_api_v1_reddit_app_fetch_post_details_get_with_http_info(post_id, **kwargs)  # noqa: E501
            return data

    def fetch_post_details_api_v1_reddit_app_fetch_post_details_get_with_http_info(self, post_id, **kwargs):  # noqa: E501
        """è·å–å•ä¸ªRedditå¸–å­è¯¦æƒ…/Fetch Single Reddit Post Details  # noqa: E501

        # [ä¸­æ–‡] ## ç”¨é€”: - æ ¹æ®å¸–å­IDè·å–å•ä¸ªå¸–å­è¯¦æƒ… - å¯é€‰æ‹©æ€§åŒ…å«ç‰¹å®šè¯„è®ºçš„ä¸Šä¸‹æ–‡  ## å‚æ•°: - post_id: å¸–å­IDï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX\" - include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºIDï¼Œé»˜è®¤False - comment_id: è¯„è®ºIDï¼ˆå½“include_comment_idä¸ºTrueæ—¶ä½¿ç”¨ï¼‰ï¼Œæ ¼å¼å¦‚ \"t1_XXXXXX\"  ## è¿”å›: - åŒ…å«å¸–å­è¯¦ç»†ä¿¡æ¯çš„æ•°æ®ï¼ŒåŒ…æ‹¬:   - å¸–å­å†…å®¹ã€æ ‡é¢˜ã€ä½œè€…   - ç»Ÿè®¡æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰   - ç‰ˆå—ä¿¡æ¯   - å¥–åŠ±ä¿¡æ¯   - åª’ä½“èµ„æº   - æ¨èåŸå› ç­‰  ## æ³¨æ„: - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnh50) - è¯„è®ºIDå‰ç¼€: t1_ (ä¾‹å¦‚: t1_abcd123)  ---  # [English] ## Purpose: - Fetch single post details by post ID - Optionally include context for specific comments  ## Parameters: - post_id: Post ID, format like \"t3_XXXXXX\" - include_comment_id: Whether to include specific comment ID, default False - comment_id: Comment ID (used when include_comment_id is True), format like \"t1_XXXXXX\"  ## Returns: - Data containing detailed post information including:   - Post content, title, author   - Statistics (upvotes, comment count, etc.)   - Subreddit information   - Award information   - Media resources   - Recommendation reasons, etc.  ## Note: - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnh50) - Comment ID prefix: t1_ (e.g., t1_abcd123)  # [ç¤ºä¾‹/Example] post_id=\"t3_1ojnh50\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_details_api_v1_reddit_app_fetch_post_details_get_with_http_info(post_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_id: å¸–å­ID/Post ID (e.g., t3_1ojnh50) (required)
        :param object include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºID/Include specific comment ID
        :param object comment_id: è¯„è®ºID/Comment ID (when include_comment_id is True)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['post_id', 'include_comment_id', 'comment_id', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_post_details_api_v1_reddit_app_fetch_post_details_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'post_id' is set
        if self.api_client.client_side_validation and ('post_id' not in params or
                                                       params['post_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `post_id` when calling `fetch_post_details_api_v1_reddit_app_fetch_post_details_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'post_id' in params:
            query_params.append(('post_id', params['post_id']))  # noqa: E501
        if 'include_comment_id' in params:
            query_params.append(('include_comment_id', params['include_comment_id']))  # noqa: E501
        if 'comment_id' in params:
            query_params.append(('comment_id', params['comment_id']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_post_details', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get(self, post_ids, **kwargs):  # noqa: E501
        """æ‰¹é‡è·å–Redditå¸–å­è¯¦æƒ…(æœ€å¤š5æ¡)/Fetch Reddit Post Details in Batch (Max 5)  # noqa: E501

        # [ä¸­æ–‡] ## ç”¨é€”: - æ ¹æ®å¸–å­IDåˆ—è¡¨æ‰¹é‡è·å–å¸–å­è¯¦æƒ… - æ”¯æŒæœ€å¤š5æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - å¯é€‰æ‹©æ€§åŒ…å«ç‰¹å®šè¯„è®ºçš„ä¸Šä¸‹æ–‡  ## å‚æ•°: - post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX,t3_YYYYYY\"ï¼Œæœ€å¤šæ”¯æŒ5æ¡ - include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºIDï¼Œé»˜è®¤False - comment_id: è¯„è®ºIDï¼ˆå½“include_comment_idä¸ºTrueæ—¶ä½¿ç”¨ï¼‰ï¼Œæ ¼å¼å¦‚ \"t1_XXXXXX\"  ## è¿”å›: - åŒ…å«å¸–å­è¯¦ç»†ä¿¡æ¯çš„æ•°æ®ï¼ŒåŒ…æ‹¬:   - å¸–å­å†…å®¹ã€æ ‡é¢˜ã€ä½œè€…   - ç»Ÿè®¡æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰   - ç‰ˆå—ä¿¡æ¯   - å¥–åŠ±ä¿¡æ¯   - åª’ä½“èµ„æº   - æ¨èåŸå› ç­‰  ## æ³¨æ„: - æœ€å¤šæ”¯æŒ5æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - è¶…è¿‡5æ¡å°†è¿”å›é”™è¯¯ - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnh50) - è¯„è®ºIDå‰ç¼€: t1_ (ä¾‹å¦‚: t1_abcd123)  ---  # [English] ## Purpose: - Fetch post details in batch by post ID list - Support batch query for up to 5 posts - Optionally include context for specific comments  ## Parameters: - post_ids: Post IDs comma-separated, format like \"t3_XXXXXX,t3_YYYYYY\", max 5 posts - include_comment_id: Whether to include specific comment ID, default False - comment_id: Comment ID (used when include_comment_id is True), format like \"t1_XXXXXX\"  ## Returns: - Data containing detailed post information including:   - Post content, title, author   - Statistics (upvotes, comment count, etc.)   - Subreddit information   - Award information   - Media resources   - Recommendation reasons, etc.  ## Notes: - Maximum 5 posts per batch query - Error will be returned if exceeds 5 posts - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnh50) - Comment ID prefix: t1_ (e.g., t1_abcd123)  # [ç¤ºä¾‹/Example] post_ids=\"t3_1ojnh50,t3_1ok432f,t3_1nwil8j\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get(post_ids, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæœ€å¤š5æ¡/Post IDs comma-separated, max 5 (e.g., t3_1ojnh50,t3_1ok432f) (required)
        :param object include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºID/Include specific comment ID
        :param object comment_id: è¯„è®ºID/Comment ID (when include_comment_id is True)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get_with_http_info(post_ids, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get_with_http_info(post_ids, **kwargs)  # noqa: E501
            return data

    def fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get_with_http_info(self, post_ids, **kwargs):  # noqa: E501
        """æ‰¹é‡è·å–Redditå¸–å­è¯¦æƒ…(æœ€å¤š5æ¡)/Fetch Reddit Post Details in Batch (Max 5)  # noqa: E501

        # [ä¸­æ–‡] ## ç”¨é€”: - æ ¹æ®å¸–å­IDåˆ—è¡¨æ‰¹é‡è·å–å¸–å­è¯¦æƒ… - æ”¯æŒæœ€å¤š5æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - å¯é€‰æ‹©æ€§åŒ…å«ç‰¹å®šè¯„è®ºçš„ä¸Šä¸‹æ–‡  ## å‚æ•°: - post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX,t3_YYYYYY\"ï¼Œæœ€å¤šæ”¯æŒ5æ¡ - include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºIDï¼Œé»˜è®¤False - comment_id: è¯„è®ºIDï¼ˆå½“include_comment_idä¸ºTrueæ—¶ä½¿ç”¨ï¼‰ï¼Œæ ¼å¼å¦‚ \"t1_XXXXXX\"  ## è¿”å›: - åŒ…å«å¸–å­è¯¦ç»†ä¿¡æ¯çš„æ•°æ®ï¼ŒåŒ…æ‹¬:   - å¸–å­å†…å®¹ã€æ ‡é¢˜ã€ä½œè€…   - ç»Ÿè®¡æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰   - ç‰ˆå—ä¿¡æ¯   - å¥–åŠ±ä¿¡æ¯   - åª’ä½“èµ„æº   - æ¨èåŸå› ç­‰  ## æ³¨æ„: - æœ€å¤šæ”¯æŒ5æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - è¶…è¿‡5æ¡å°†è¿”å›é”™è¯¯ - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnh50) - è¯„è®ºIDå‰ç¼€: t1_ (ä¾‹å¦‚: t1_abcd123)  ---  # [English] ## Purpose: - Fetch post details in batch by post ID list - Support batch query for up to 5 posts - Optionally include context for specific comments  ## Parameters: - post_ids: Post IDs comma-separated, format like \"t3_XXXXXX,t3_YYYYYY\", max 5 posts - include_comment_id: Whether to include specific comment ID, default False - comment_id: Comment ID (used when include_comment_id is True), format like \"t1_XXXXXX\"  ## Returns: - Data containing detailed post information including:   - Post content, title, author   - Statistics (upvotes, comment count, etc.)   - Subreddit information   - Award information   - Media resources   - Recommendation reasons, etc.  ## Notes: - Maximum 5 posts per batch query - Error will be returned if exceeds 5 posts - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnh50) - Comment ID prefix: t1_ (e.g., t1_abcd123)  # [ç¤ºä¾‹/Example] post_ids=\"t3_1ojnh50,t3_1ok432f,t3_1nwil8j\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get_with_http_info(post_ids, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæœ€å¤š5æ¡/Post IDs comma-separated, max 5 (e.g., t3_1ojnh50,t3_1ok432f) (required)
        :param object include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºID/Include specific comment ID
        :param object comment_id: è¯„è®ºID/Comment ID (when include_comment_id is True)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['post_ids', 'include_comment_id', 'comment_id', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'post_ids' is set
        if self.api_client.client_side_validation and ('post_ids' not in params or
                                                       params['post_ids'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `post_ids` when calling `fetch_post_details_batch_api_v1_reddit_app_fetch_post_details_batch_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'post_ids' in params:
            query_params.append(('post_ids', params['post_ids']))  # noqa: E501
        if 'include_comment_id' in params:
            query_params.append(('include_comment_id', params['include_comment_id']))  # noqa: E501
        if 'comment_id' in params:
            query_params.append(('comment_id', params['comment_id']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_post_details_batch', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get(self, post_ids, **kwargs):  # noqa: E501
        """å¤§æ‰¹é‡è·å–Redditå¸–å­è¯¦æƒ…(æœ€å¤š30æ¡)/Fetch Reddit Post Details in Large Batch (Max 30)  # noqa: E501

        # [ä¸­æ–‡] ## ç”¨é€”: - æ ¹æ®å¸–å­IDåˆ—è¡¨å¤§æ‰¹é‡è·å–å¸–å­è¯¦æƒ… - æ”¯æŒæœ€å¤š30æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - å¯é€‰æ‹©æ€§åŒ…å«ç‰¹å®šè¯„è®ºçš„ä¸Šä¸‹æ–‡  ## å‚æ•°: - post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX,t3_YYYYYY,...\"ï¼Œæœ€å¤šæ”¯æŒ30æ¡ - include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºIDï¼Œé»˜è®¤False - comment_id: è¯„è®ºIDï¼ˆå½“include_comment_idä¸ºTrueæ—¶ä½¿ç”¨ï¼‰ï¼Œæ ¼å¼å¦‚ \"t1_XXXXXX\"  ## è¿”å›: - åŒ…å«å¸–å­è¯¦ç»†ä¿¡æ¯çš„æ•°æ®ï¼ŒåŒ…æ‹¬:   - å¸–å­å†…å®¹ã€æ ‡é¢˜ã€ä½œè€…   - ç»Ÿè®¡æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰   - ç‰ˆå—ä¿¡æ¯   - å¥–åŠ±ä¿¡æ¯   - åª’ä½“èµ„æº   - æ¨èåŸå› ç­‰  ## æ³¨æ„: - æœ€å¤šæ”¯æŒ30æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - è¶…è¿‡30æ¡å°†è¿”å›é”™è¯¯ - å¤§æ‰¹é‡æŸ¥è¯¢å¯èƒ½éœ€è¦è¾ƒé•¿çš„å“åº”æ—¶é—´ - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnh50) - è¯„è®ºIDå‰ç¼€: t1_ (ä¾‹å¦‚: t1_abcd123)  ---  # [English] ## Purpose: - Fetch post details in large batch by post ID list - Support batch query for up to 30 posts - Optionally include context for specific comments  ## Parameters: - post_ids: Post IDs comma-separated, format like \"t3_XXXXXX,t3_YYYYYY,...\", max 30 posts - include_comment_id: Whether to include specific comment ID, default False - comment_id: Comment ID (used when include_comment_id is True), format like \"t1_XXXXXX\"  ## Returns: - Data containing detailed post information including:   - Post content, title, author   - Statistics (upvotes, comment count, etc.)   - Subreddit information   - Award information   - Media resources   - Recommendation reasons, etc.  ## Notes: - Maximum 30 posts per batch query - Error will be returned if exceeds 30 posts - Large batch queries may take longer to respond - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnh50) - Comment ID prefix: t1_ (e.g., t1_abcd123)  # [ç¤ºä¾‹/Example] post_ids=\"t3_1ojnh50,t3_1ok432f,t3_1nwil8j,t3_1oj6vn6,t3_1nuenmd,...\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get(post_ids, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæœ€å¤š30æ¡/Post IDs comma-separated, max 30 (e.g., t3_1ojnh50,t3_1ok432f,...) (required)
        :param object include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºID/Include specific comment ID
        :param object comment_id: è¯„è®ºID/Comment ID (when include_comment_id is True)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get_with_http_info(post_ids, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get_with_http_info(post_ids, **kwargs)  # noqa: E501
            return data

    def fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get_with_http_info(self, post_ids, **kwargs):  # noqa: E501
        """å¤§æ‰¹é‡è·å–Redditå¸–å­è¯¦æƒ…(æœ€å¤š30æ¡)/Fetch Reddit Post Details in Large Batch (Max 30)  # noqa: E501

        # [ä¸­æ–‡] ## ç”¨é€”: - æ ¹æ®å¸–å­IDåˆ—è¡¨å¤§æ‰¹é‡è·å–å¸–å­è¯¦æƒ… - æ”¯æŒæœ€å¤š30æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - å¯é€‰æ‹©æ€§åŒ…å«ç‰¹å®šè¯„è®ºçš„ä¸Šä¸‹æ–‡  ## å‚æ•°: - post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæ ¼å¼å¦‚ \"t3_XXXXXX,t3_YYYYYY,...\"ï¼Œæœ€å¤šæ”¯æŒ30æ¡ - include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºIDï¼Œé»˜è®¤False - comment_id: è¯„è®ºIDï¼ˆå½“include_comment_idä¸ºTrueæ—¶ä½¿ç”¨ï¼‰ï¼Œæ ¼å¼å¦‚ \"t1_XXXXXX\"  ## è¿”å›: - åŒ…å«å¸–å­è¯¦ç»†ä¿¡æ¯çš„æ•°æ®ï¼ŒåŒ…æ‹¬:   - å¸–å­å†…å®¹ã€æ ‡é¢˜ã€ä½œè€…   - ç»Ÿè®¡æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰   - ç‰ˆå—ä¿¡æ¯   - å¥–åŠ±ä¿¡æ¯   - åª’ä½“èµ„æº   - æ¨èåŸå› ç­‰  ## æ³¨æ„: - æœ€å¤šæ”¯æŒ30æ¡å¸–å­çš„æ‰¹é‡æŸ¥è¯¢ - è¶…è¿‡30æ¡å°†è¿”å›é”™è¯¯ - å¤§æ‰¹é‡æŸ¥è¯¢å¯èƒ½éœ€è¦è¾ƒé•¿çš„å“åº”æ—¶é—´ - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - å¸–å­IDå‰ç¼€: t3_ (ä¾‹å¦‚: t3_1ojnh50) - è¯„è®ºIDå‰ç¼€: t1_ (ä¾‹å¦‚: t1_abcd123)  ---  # [English] ## Purpose: - Fetch post details in large batch by post ID list - Support batch query for up to 30 posts - Optionally include context for specific comments  ## Parameters: - post_ids: Post IDs comma-separated, format like \"t3_XXXXXX,t3_YYYYYY,...\", max 30 posts - include_comment_id: Whether to include specific comment ID, default False - comment_id: Comment ID (used when include_comment_id is True), format like \"t1_XXXXXX\"  ## Returns: - Data containing detailed post information including:   - Post content, title, author   - Statistics (upvotes, comment count, etc.)   - Subreddit information   - Award information   - Media resources   - Recommendation reasons, etc.  ## Notes: - Maximum 30 posts per batch query - Error will be returned if exceeds 30 posts - Large batch queries may take longer to respond - **APP API ID format differs from Web API, requires type prefix** - Post ID prefix: t3_ (e.g., t3_1ojnh50) - Comment ID prefix: t1_ (e.g., t1_abcd123)  # [ç¤ºä¾‹/Example] post_ids=\"t3_1ojnh50,t3_1ok432f,t3_1nwil8j,t3_1oj6vn6,t3_1nuenmd,...\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get_with_http_info(post_ids, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object post_ids: å¸–å­IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œæœ€å¤š30æ¡/Post IDs comma-separated, max 30 (e.g., t3_1ojnh50,t3_1ok432f,...) (required)
        :param object include_comment_id: æ˜¯å¦åŒ…å«ç‰¹å®šè¯„è®ºID/Include specific comment ID
        :param object comment_id: è¯„è®ºID/Comment ID (when include_comment_id is True)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['post_ids', 'include_comment_id', 'comment_id', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'post_ids' is set
        if self.api_client.client_side_validation and ('post_ids' not in params or
                                                       params['post_ids'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `post_ids` when calling `fetch_post_details_batch_large_api_v1_reddit_app_fetch_post_details_batch_large_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'post_ids' in params:
            query_params.append(('post_ids', params['post_ids']))  # noqa: E501
        if 'include_comment_id' in params:
            query_params.append(('include_comment_id', params['include_comment_id']))  # noqa: E501
        if 'comment_id' in params:
            query_params.append(('comment_id', params['comment_id']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_post_details_batch_large', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get(self, query, **kwargs):  # noqa: E501
        """è·å–Reddit APPæœç´¢è‡ªåŠ¨è¡¥å…¨å»ºè®®/Fetch Reddit APP Search Typeahead Suggestions  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæœç´¢æ¡†çš„è‡ªåŠ¨è¡¥å…¨å»ºè®®,åŒ…æ‹¬æ¨èçš„ç‰ˆå—ã€ç”¨æˆ·å’Œæœç´¢è¯ ### å‚æ•°: - query: æœç´¢å…³é”®è¯,è¾“å…¥çš„æœç´¢æ–‡æœ¬ - safe_search: å®‰å…¨æœç´¢è®¾ç½®,å¯é€‰å€¼ä¸º\"unset\"(æœªè®¾ç½®)æˆ–\"strict\"(ä¸¥æ ¼æ¨¡å¼) - allow_nsfw: æ˜¯å¦å…è®¸æ˜¾ç¤ºNSFW(æˆäºº)å†…å®¹,\"0\"è¡¨ç¤ºä¸å…è®¸,\"1\"è¡¨ç¤ºå…è®¸ ### è¿”å›: - æœç´¢å»ºè®®JSONæ•°æ®,åŒ…å«ä»¥ä¸‹ç±»å‹çš„å»ºè®®:   - ç›¸å…³ç‰ˆå—(subreddits)   - ç›¸å…³ç”¨æˆ·(users)   - æœç´¢è¯å»ºè®®(search suggestions)   - çƒ­é—¨è¯é¢˜(trending topics)  # [English] ### Purpose: - Fetch autocomplete suggestions for the Reddit APP search box, including recommended subreddits, users, and search terms ### Parameters: - query: Search keyword, the search text being typed - safe_search: Safe search setting, options are \"unset\" or \"strict\" - allow_nsfw: Whether to allow NSFW (adult) content display, \"0\" means disallow, \"1\" means allow ### Returns: - JSON data of search suggestions containing the following types:   - Related subreddits   - Related users   - Search term suggestions   - Trending topics  # [ç¤ºä¾‹/Example] query=\"programming\" safe_search=\"unset\" allow_nsfw=\"0\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get(query, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object query: æœç´¢å…³é”®è¯/Search query (required)
        :param object safe_search: å®‰å…¨æœç´¢è®¾ç½®/Safe search setting: unset, strict
        :param object allow_nsfw: æ˜¯å¦å…è®¸NSFWå†…å®¹/Allow NSFW content: 0 or 1
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get_with_http_info(query, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get_with_http_info(query, **kwargs)  # noqa: E501
            return data

    def fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get_with_http_info(self, query, **kwargs):  # noqa: E501
        """è·å–Reddit APPæœç´¢è‡ªåŠ¨è¡¥å…¨å»ºè®®/Fetch Reddit APP Search Typeahead Suggestions  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæœç´¢æ¡†çš„è‡ªåŠ¨è¡¥å…¨å»ºè®®,åŒ…æ‹¬æ¨èçš„ç‰ˆå—ã€ç”¨æˆ·å’Œæœç´¢è¯ ### å‚æ•°: - query: æœç´¢å…³é”®è¯,è¾“å…¥çš„æœç´¢æ–‡æœ¬ - safe_search: å®‰å…¨æœç´¢è®¾ç½®,å¯é€‰å€¼ä¸º\"unset\"(æœªè®¾ç½®)æˆ–\"strict\"(ä¸¥æ ¼æ¨¡å¼) - allow_nsfw: æ˜¯å¦å…è®¸æ˜¾ç¤ºNSFW(æˆäºº)å†…å®¹,\"0\"è¡¨ç¤ºä¸å…è®¸,\"1\"è¡¨ç¤ºå…è®¸ ### è¿”å›: - æœç´¢å»ºè®®JSONæ•°æ®,åŒ…å«ä»¥ä¸‹ç±»å‹çš„å»ºè®®:   - ç›¸å…³ç‰ˆå—(subreddits)   - ç›¸å…³ç”¨æˆ·(users)   - æœç´¢è¯å»ºè®®(search suggestions)   - çƒ­é—¨è¯é¢˜(trending topics)  # [English] ### Purpose: - Fetch autocomplete suggestions for the Reddit APP search box, including recommended subreddits, users, and search terms ### Parameters: - query: Search keyword, the search text being typed - safe_search: Safe search setting, options are \"unset\" or \"strict\" - allow_nsfw: Whether to allow NSFW (adult) content display, \"0\" means disallow, \"1\" means allow ### Returns: - JSON data of search suggestions containing the following types:   - Related subreddits   - Related users   - Search term suggestions   - Trending topics  # [ç¤ºä¾‹/Example] query=\"programming\" safe_search=\"unset\" allow_nsfw=\"0\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get_with_http_info(query, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object query: æœç´¢å…³é”®è¯/Search query (required)
        :param object safe_search: å®‰å…¨æœç´¢è®¾ç½®/Safe search setting: unset, strict
        :param object allow_nsfw: æ˜¯å¦å…è®¸NSFWå†…å®¹/Allow NSFW content: 0 or 1
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['query', 'safe_search', 'allow_nsfw', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'query' is set
        if self.api_client.client_side_validation and ('query' not in params or
                                                       params['query'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `query` when calling `fetch_search_typeahead_api_v1_reddit_app_fetch_search_typeahead_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'query' in params:
            query_params.append(('query', params['query']))  # noqa: E501
        if 'safe_search' in params:
            query_params.append(('safe_search', params['safe_search']))  # noqa: E501
        if 'allow_nsfw' in params:
            query_params.append(('allow_nsfw', params['allow_nsfw']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_search_typeahead', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get(self, subreddit_name, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—Feedå†…å®¹/Fetch Reddit APP Subreddit Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šRedditç‰ˆå—çš„Feedå†…å®¹æµ,å±•ç¤ºè¯¥ç‰ˆå—çš„å¸–å­åˆ—è¡¨ ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€),å¦‚\"pics\", \"funny\"ç­‰ - sort: æ’åºæ–¹å¼,å¯é€‰: BEST(æœ€ä½³), HOT(çƒ­é—¨), NEW(æœ€æ–°), TOP(é¡¶çº§), CONTROVERSIAL(æœ‰äº‰è®®), RISING(ä¸Šå‡ä¸­) - filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨ - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - ç‰ˆå—Feed JSONæ•°æ®,åŒ…å«:   - è¯¥ç‰ˆå—çš„å¸–å­åˆ—è¡¨   - å¸–å­è¯¦ç»†ä¿¡æ¯   - ç‰ˆå—å…ƒæ•°æ®   - åˆ†é¡µä¿¡æ¯  # [English] ### Purpose: - Fetch feed content stream of a specified Reddit subreddit, displaying the post list of that subreddit ### Parameters: - subreddit_name: Subreddit name (without r/ prefix), e.g., \"pics\", \"funny\" - sort: Sort method, options: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING - filter_posts: List of post IDs to filter out - after: Pagination parameter for fetching next page ### Returns: - JSON data of subreddit feed containing:   - List of posts in the subreddit   - Detailed post information   - Subreddit metadata   - Pagination information  # [ç¤ºä¾‹/Example] subreddit_name=\"AskReddit\" sort=\"HOT\" filter_posts=[] after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get(subreddit_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name (required)
        :param object sort: æ’åºæ–¹å¼/Sort method: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING
        :param object filter_posts: è¿‡æ»¤å¸–å­IDåˆ—è¡¨/Filter post IDs
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get_with_http_info(subreddit_name, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get_with_http_info(subreddit_name, **kwargs)  # noqa: E501
            return data

    def fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get_with_http_info(self, subreddit_name, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—Feedå†…å®¹/Fetch Reddit APP Subreddit Feed  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šRedditç‰ˆå—çš„Feedå†…å®¹æµ,å±•ç¤ºè¯¥ç‰ˆå—çš„å¸–å­åˆ—è¡¨ ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€),å¦‚\"pics\", \"funny\"ç­‰ - sort: æ’åºæ–¹å¼,å¯é€‰: BEST(æœ€ä½³), HOT(çƒ­é—¨), NEW(æœ€æ–°), TOP(é¡¶çº§), CONTROVERSIAL(æœ‰äº‰è®®), RISING(ä¸Šå‡ä¸­) - filter_posts: è¿‡æ»¤æ‰æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨ - after: åˆ†é¡µå‚æ•°,è·å–ä¸‹ä¸€é¡µæ—¶ä½¿ç”¨ ### è¿”å›: - ç‰ˆå—Feed JSONæ•°æ®,åŒ…å«:   - è¯¥ç‰ˆå—çš„å¸–å­åˆ—è¡¨   - å¸–å­è¯¦ç»†ä¿¡æ¯   - ç‰ˆå—å…ƒæ•°æ®   - åˆ†é¡µä¿¡æ¯  # [English] ### Purpose: - Fetch feed content stream of a specified Reddit subreddit, displaying the post list of that subreddit ### Parameters: - subreddit_name: Subreddit name (without r/ prefix), e.g., \"pics\", \"funny\" - sort: Sort method, options: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING - filter_posts: List of post IDs to filter out - after: Pagination parameter for fetching next page ### Returns: - JSON data of subreddit feed containing:   - List of posts in the subreddit   - Detailed post information   - Subreddit metadata   - Pagination information  # [ç¤ºä¾‹/Example] subreddit_name=\"AskReddit\" sort=\"HOT\" filter_posts=[] after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get_with_http_info(subreddit_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name (required)
        :param object sort: æ’åºæ–¹å¼/Sort method: BEST, HOT, NEW, TOP, CONTROVERSIAL, RISING
        :param object filter_posts: è¿‡æ»¤å¸–å­IDåˆ—è¡¨/Filter post IDs
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subreddit_name', 'sort', 'filter_posts', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'subreddit_name' is set
        if self.api_client.client_side_validation and ('subreddit_name' not in params or
                                                       params['subreddit_name'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `subreddit_name` when calling `fetch_subreddit_feed_api_v1_reddit_app_fetch_subreddit_feed_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subreddit_name' in params:
            query_params.append(('subreddit_name', params['subreddit_name']))  # noqa: E501
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'filter_posts' in params:
            query_params.append(('filter_posts', params['filter_posts']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_subreddit_feed', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_subreddit_info_api_v1_reddit_app_fetch_subreddit_info_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—ä¿¡æ¯/Fetch Reddit APP Subreddit Info  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬ç‰ˆå—æè¿°ã€æˆå‘˜æ•°é‡ã€åˆ›å»ºæ—¶é—´ã€è§„åˆ™ç­‰å…ƒæ•°æ® ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€),ä¾‹å¦‚\"pics\", \"funny\", \"AskReddit\"ç­‰ ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„è¯¦ç»†ä¿¡æ¯JSONæ•°æ® # [English] ### Purpose: - Fetch detailed information of a specified Reddit APP subreddit, including description, subscriber count, creation time, rules, and other metadata ### Parameters: - subreddit_name: Subreddit name (without r/ prefix), e.g., \"pics\", \"funny\", \"AskReddit\" ### Returns: - JSON data containing detailed subreddit information  # [ç¤ºä¾‹/Example] subreddit_name=\"pics\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_info_api_v1_reddit_app_fetch_subreddit_info_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_subreddit_info_api_v1_reddit_app_fetch_subreddit_info_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_subreddit_info_api_v1_reddit_app_fetch_subreddit_info_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_subreddit_info_api_v1_reddit_app_fetch_subreddit_info_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—ä¿¡æ¯/Fetch Reddit APP Subreddit Info  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬ç‰ˆå—æè¿°ã€æˆå‘˜æ•°é‡ã€åˆ›å»ºæ—¶é—´ã€è§„åˆ™ç­‰å…ƒæ•°æ® ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€),ä¾‹å¦‚\"pics\", \"funny\", \"AskReddit\"ç­‰ ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„è¯¦ç»†ä¿¡æ¯JSONæ•°æ® # [English] ### Purpose: - Fetch detailed information of a specified Reddit APP subreddit, including description, subscriber count, creation time, rules, and other metadata ### Parameters: - subreddit_name: Subreddit name (without r/ prefix), e.g., \"pics\", \"funny\", \"AskReddit\" ### Returns: - JSON data containing detailed subreddit information  # [ç¤ºä¾‹/Example] subreddit_name=\"pics\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_info_api_v1_reddit_app_fetch_subreddit_info_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subreddit_name', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_subreddit_info_api_v1_reddit_app_fetch_subreddit_info_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subreddit_name' in params:
            query_params.append(('subreddit_name', params['subreddit_name']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_subreddit_info', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_subreddit_post_channels_api_v1_reddit_app_fetch_subreddit_post_channels_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—å¸–å­é¢‘é“ä¿¡æ¯/Fetch Reddit APP Subreddit Post Channels  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„å¸–å­é¢‘é“ä¿¡æ¯ ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€) - sort: æ’åºæ–¹å¼ï¼Œæ”¯æŒHOT, NEW, TOP, CONTROVERSIAL, RISING - range: æ—¶é—´èŒƒå›´ï¼Œæ”¯æŒHOUR, DAY, WEEK, MONTH, YEAR, ALL ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„å¸–å­é¢‘é“ä¿¡æ¯JSONæ•°æ®  # [English] ### Purpose: - Fetch post channel information of a specified Reddit APP subreddit ### Parameters: - subreddit_name: Subreddit name - sort: Sort method, supports HOT, NEW, TOP, CONTROVERSIAL, RISING - range: Time range, supports HOUR, DAY, WEEK, MONTH, YEAR, ALL ### Returns: - JSON data of post channel information of the specified subreddit  # [ç¤ºä¾‹/Example] subreddit_name=\"pics\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_post_channels_api_v1_reddit_app_fetch_subreddit_post_channels_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name
        :param object sort: æ’åºæ–¹å¼/Sort method: HOT, NEW, TOP, CONTROVERSIAL, RISING
        :param object range: æ—¶é—´èŒƒå›´/Time range: HOUR, DAY, WEEK, MONTH, YEAR, ALL
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_subreddit_post_channels_api_v1_reddit_app_fetch_subreddit_post_channels_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_subreddit_post_channels_api_v1_reddit_app_fetch_subreddit_post_channels_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_subreddit_post_channels_api_v1_reddit_app_fetch_subreddit_post_channels_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—å¸–å­é¢‘é“ä¿¡æ¯/Fetch Reddit APP Subreddit Post Channels  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„å¸–å­é¢‘é“ä¿¡æ¯ ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€) - sort: æ’åºæ–¹å¼ï¼Œæ”¯æŒHOT, NEW, TOP, CONTROVERSIAL, RISING - range: æ—¶é—´èŒƒå›´ï¼Œæ”¯æŒHOUR, DAY, WEEK, MONTH, YEAR, ALL ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„å¸–å­é¢‘é“ä¿¡æ¯JSONæ•°æ®  # [English] ### Purpose: - Fetch post channel information of a specified Reddit APP subreddit ### Parameters: - subreddit_name: Subreddit name - sort: Sort method, supports HOT, NEW, TOP, CONTROVERSIAL, RISING - range: Time range, supports HOUR, DAY, WEEK, MONTH, YEAR, ALL ### Returns: - JSON data of post channel information of the specified subreddit  # [ç¤ºä¾‹/Example] subreddit_name=\"pics\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_post_channels_api_v1_reddit_app_fetch_subreddit_post_channels_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name
        :param object sort: æ’åºæ–¹å¼/Sort method: HOT, NEW, TOP, CONTROVERSIAL, RISING
        :param object range: æ—¶é—´èŒƒå›´/Time range: HOUR, DAY, WEEK, MONTH, YEAR, ALL
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subreddit_name', 'sort', 'range', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_subreddit_post_channels_api_v1_reddit_app_fetch_subreddit_post_channels_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subreddit_name' in params:
            query_params.append(('subreddit_name', params['subreddit_name']))  # noqa: E501
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'range' in params:
            query_params.append(('range', params['range']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_subreddit_post_channels', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get(self, subreddit_id, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—è®¾ç½®/Fetch Reddit APP Subreddit Settings  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„è®¾ç½®ä¿¡æ¯,åŒ…æ‹¬å‘å¸–è§„åˆ™ã€ç”¨æˆ·æ ‡ç­¾è®¾ç½®ã€å®¡æ ¸è®¾ç½®ç­‰é…ç½®ä¿¡æ¯ ### å‚æ•°: - subreddit_id: ç‰ˆå—ID,æ ¼å¼ä¸ºt5_å¼€å¤´çš„å”¯ä¸€æ ‡è¯†ç¬¦,ä¾‹å¦‚\"t5_2qh0u\"(å¯ä»fetch_subreddit_infoæ¥å£è·å–ç‰ˆå—ID) ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„è®¾ç½®ä¿¡æ¯JSONæ•°æ®,åŒ…å«ä»¥ä¸‹ä¸»è¦å­—æ®µ:   - subredditType: ç‰ˆå—ç±»å‹(public/private/restricted)   - submissionType: å…è®¸æäº¤çš„å†…å®¹ç±»å‹(any/link/self)   - allowImages: æ˜¯å¦å…è®¸å›¾ç‰‡   - allowVideos: æ˜¯å¦å…è®¸è§†é¢‘   - allowPolls: æ˜¯å¦å…è®¸æŠ•ç¥¨   - suggestedCommentSort: å»ºè®®çš„è¯„è®ºæ’åºæ–¹å¼   - spoilersEnabled: æ˜¯å¦å¯ç”¨å‰§é€æ ‡è®°   - allowedPostTypes: å…è®¸çš„å¸–å­ç±»å‹é…ç½®   - contentOptions: å†…å®¹é€‰é¡¹è®¾ç½®   - flairSettings: ç”¨æˆ·/å¸–å­æ ‡ç­¾è®¾ç½® ### æ³¨æ„äº‹é¡¹: - éœ€è¦å…ˆé€šè¿‡fetch_subreddit_infoæ¥å£è·å–ç‰ˆå—ID(subreddit.idå­—æ®µ) - ç‰ˆå—IDæ ¼å¼å¿…é¡»ä¸º\"t5_\"å¼€å¤´ - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - ç‰ˆå—IDå‰ç¼€: t5_ (ä¾‹å¦‚: t5_2qh0u)  # [English] ### Purpose: - Fetch settings information of a specified Reddit APP subreddit, including posting rules, flair settings, moderation settings, and other configurations ### Parameters: - subreddit_id: Subreddit ID with format starting with t5_, e.g., \"t5_2qh0u\" (can be obtained from the fetch_subreddit_info endpoint) ### Returns: - JSON data containing subreddit settings with the following main fields:   - subredditType: Subreddit type (public/private/restricted)   - submissionType: Allowed submission content types (any/link/self)   - allowImages: Whether images are allowed   - allowVideos: Whether videos are allowed   - allowPolls: Whether polls are allowed   - suggestedCommentSort: Suggested comment sort method   - spoilersEnabled: Whether spoiler tags are enabled   - allowedPostTypes: Allowed post types configuration   - contentOptions: Content options settings   - flairSettings: User/post flair settings ### Notes: - You need to first get the subreddit ID (subreddit.id field) via the fetch_subreddit_info endpoint - Subreddit ID format must start with \"t5_\" - **APP API ID format differs from Web API, requires type prefix** - Subreddit ID prefix: t5_ (e.g., t5_2qh0u)  # [ç¤ºä¾‹/Example] subreddit_id=\"t5_2qh0u\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get(subreddit_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_id: ç‰ˆå—ID/Subreddit ID (format: t5_xxxxx) (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get_with_http_info(subreddit_id, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get_with_http_info(subreddit_id, **kwargs)  # noqa: E501
            return data

    def fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get_with_http_info(self, subreddit_id, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—è®¾ç½®/Fetch Reddit APP Subreddit Settings  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„è®¾ç½®ä¿¡æ¯,åŒ…æ‹¬å‘å¸–è§„åˆ™ã€ç”¨æˆ·æ ‡ç­¾è®¾ç½®ã€å®¡æ ¸è®¾ç½®ç­‰é…ç½®ä¿¡æ¯ ### å‚æ•°: - subreddit_id: ç‰ˆå—ID,æ ¼å¼ä¸ºt5_å¼€å¤´çš„å”¯ä¸€æ ‡è¯†ç¬¦,ä¾‹å¦‚\"t5_2qh0u\"(å¯ä»fetch_subreddit_infoæ¥å£è·å–ç‰ˆå—ID) ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„è®¾ç½®ä¿¡æ¯JSONæ•°æ®,åŒ…å«ä»¥ä¸‹ä¸»è¦å­—æ®µ:   - subredditType: ç‰ˆå—ç±»å‹(public/private/restricted)   - submissionType: å…è®¸æäº¤çš„å†…å®¹ç±»å‹(any/link/self)   - allowImages: æ˜¯å¦å…è®¸å›¾ç‰‡   - allowVideos: æ˜¯å¦å…è®¸è§†é¢‘   - allowPolls: æ˜¯å¦å…è®¸æŠ•ç¥¨   - suggestedCommentSort: å»ºè®®çš„è¯„è®ºæ’åºæ–¹å¼   - spoilersEnabled: æ˜¯å¦å¯ç”¨å‰§é€æ ‡è®°   - allowedPostTypes: å…è®¸çš„å¸–å­ç±»å‹é…ç½®   - contentOptions: å†…å®¹é€‰é¡¹è®¾ç½®   - flairSettings: ç”¨æˆ·/å¸–å­æ ‡ç­¾è®¾ç½® ### æ³¨æ„äº‹é¡¹: - éœ€è¦å…ˆé€šè¿‡fetch_subreddit_infoæ¥å£è·å–ç‰ˆå—ID(subreddit.idå­—æ®µ) - ç‰ˆå—IDæ ¼å¼å¿…é¡»ä¸º\"t5_\"å¼€å¤´ - **APPæ¥å£çš„IDæ ¼å¼ä¸Webæ¥å£ä¸åŒï¼Œéœ€è¦æ·»åŠ ç±»å‹å‰ç¼€** - ç‰ˆå—IDå‰ç¼€: t5_ (ä¾‹å¦‚: t5_2qh0u)  # [English] ### Purpose: - Fetch settings information of a specified Reddit APP subreddit, including posting rules, flair settings, moderation settings, and other configurations ### Parameters: - subreddit_id: Subreddit ID with format starting with t5_, e.g., \"t5_2qh0u\" (can be obtained from the fetch_subreddit_info endpoint) ### Returns: - JSON data containing subreddit settings with the following main fields:   - subredditType: Subreddit type (public/private/restricted)   - submissionType: Allowed submission content types (any/link/self)   - allowImages: Whether images are allowed   - allowVideos: Whether videos are allowed   - allowPolls: Whether polls are allowed   - suggestedCommentSort: Suggested comment sort method   - spoilersEnabled: Whether spoiler tags are enabled   - allowedPostTypes: Allowed post types configuration   - contentOptions: Content options settings   - flairSettings: User/post flair settings ### Notes: - You need to first get the subreddit ID (subreddit.id field) via the fetch_subreddit_info endpoint - Subreddit ID format must start with \"t5_\" - **APP API ID format differs from Web API, requires type prefix** - Subreddit ID prefix: t5_ (e.g., t5_2qh0u)  # [ç¤ºä¾‹/Example] subreddit_id=\"t5_2qh0u\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get_with_http_info(subreddit_id, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_id: ç‰ˆå—ID/Subreddit ID (format: t5_xxxxx) (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subreddit_id', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'subreddit_id' is set
        if self.api_client.client_side_validation and ('subreddit_id' not in params or
                                                       params['subreddit_id'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `subreddit_id` when calling `fetch_subreddit_settings_api_v1_reddit_app_fetch_subreddit_settings_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subreddit_id' in params:
            query_params.append(('subreddit_id', params['subreddit_id']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_subreddit_settings', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_subreddit_style_api_v1_reddit_app_fetch_subreddit_style_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—è§„åˆ™æ ·å¼ä¿¡æ¯/Fetch Reddit APP Subreddit Rules and Style Info  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„è§„åˆ™å’Œæ ·å¼ä¿¡æ¯ ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€) ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„è§„åˆ™å’Œæ ·å¼ä¿¡æ¯JSONæ•°æ®  # [English] ### Purpose: - Fetch rules and style information of a specified Reddit APP subreddit ### Parameters: - subreddit_name: Subreddit name ### Returns: - JSON data of rules and style information of the specified subreddit  # [ç¤ºä¾‹/Example] subreddit_name=\"pics\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_style_api_v1_reddit_app_fetch_subreddit_style_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_subreddit_style_api_v1_reddit_app_fetch_subreddit_style_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_subreddit_style_api_v1_reddit_app_fetch_subreddit_style_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_subreddit_style_api_v1_reddit_app_fetch_subreddit_style_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPç‰ˆå—è§„åˆ™æ ·å¼ä¿¡æ¯/Fetch Reddit APP Subreddit Rules and Style Info  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç‰ˆå—çš„è§„åˆ™å’Œæ ·å¼ä¿¡æ¯ ### å‚æ•°: - subreddit_name: ç‰ˆå—åç§°(ä¸å¸¦r/å‰ç¼€) ### è¿”å›: - æŒ‡å®šç‰ˆå—çš„è§„åˆ™å’Œæ ·å¼ä¿¡æ¯JSONæ•°æ®  # [English] ### Purpose: - Fetch rules and style information of a specified Reddit APP subreddit ### Parameters: - subreddit_name: Subreddit name ### Returns: - JSON data of rules and style information of the specified subreddit  # [ç¤ºä¾‹/Example] subreddit_name=\"pics\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_subreddit_style_api_v1_reddit_app_fetch_subreddit_style_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object subreddit_name: ç‰ˆå—åç§°/Subreddit name
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['subreddit_name', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_subreddit_style_api_v1_reddit_app_fetch_subreddit_style_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'subreddit_name' in params:
            query_params.append(('subreddit_name', params['subreddit_name']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_subreddit_style', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_trending_searches_api_v1_reddit_app_fetch_trending_searches_get(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPä»Šæ—¥çƒ­é—¨æœç´¢/Fetch Reddit APP Trending Searches  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPå½“å‰çƒ­é—¨æœç´¢è¯é¢˜å’Œè¶‹åŠ¿å†…å®¹ ### å‚æ•°: - æ— éœ€å‚æ•° ### è¿”å›: - çƒ­é—¨æœç´¢JSONæ•°æ®,åŒ…å«:   - çƒ­é—¨æœç´¢å…³é”®è¯åˆ—è¡¨   - è¶‹åŠ¿è¯é¢˜   - æ¯ä¸ªè¯é¢˜çš„æœç´¢é‡å’Œçƒ­åº¦   - ç›¸å…³å¸–å­é¢„è§ˆ  # [English] ### Purpose: - Fetch currently trending search topics and content on Reddit APP ### Parameters: - No parameters required ### Returns: - JSON data of trending searches containing:   - List of trending search keywords   - Trending topics   - Search volume and popularity for each topic   - Related post previews  # [ç¤ºä¾‹/Example] æ— éœ€å‚æ•°/No parameters required  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_trending_searches_api_v1_reddit_app_fetch_trending_searches_get(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_trending_searches_api_v1_reddit_app_fetch_trending_searches_get_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.fetch_trending_searches_api_v1_reddit_app_fetch_trending_searches_get_with_http_info(**kwargs)  # noqa: E501
            return data

    def fetch_trending_searches_api_v1_reddit_app_fetch_trending_searches_get_with_http_info(self, **kwargs):  # noqa: E501
        """è·å–Reddit APPä»Šæ—¥çƒ­é—¨æœç´¢/Fetch Reddit APP Trending Searches  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPå½“å‰çƒ­é—¨æœç´¢è¯é¢˜å’Œè¶‹åŠ¿å†…å®¹ ### å‚æ•°: - æ— éœ€å‚æ•° ### è¿”å›: - çƒ­é—¨æœç´¢JSONæ•°æ®,åŒ…å«:   - çƒ­é—¨æœç´¢å…³é”®è¯åˆ—è¡¨   - è¶‹åŠ¿è¯é¢˜   - æ¯ä¸ªè¯é¢˜çš„æœç´¢é‡å’Œçƒ­åº¦   - ç›¸å…³å¸–å­é¢„è§ˆ  # [English] ### Purpose: - Fetch currently trending search topics and content on Reddit APP ### Parameters: - No parameters required ### Returns: - JSON data of trending searches containing:   - List of trending search keywords   - Trending topics   - Search volume and popularity for each topic   - Related post previews  # [ç¤ºä¾‹/Example] æ— éœ€å‚æ•°/No parameters required  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_trending_searches_api_v1_reddit_app_fetch_trending_searches_get_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_trending_searches_api_v1_reddit_app_fetch_trending_searches_get" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_trending_searches', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·æ´»è·ƒçš„ç¤¾åŒºåˆ—è¡¨/Fetch User's Active Subreddits  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šç”¨æˆ·æœ€æ´»è·ƒçš„Redditç¤¾åŒºåˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å ### è¿”å›: - ç”¨æˆ·æ´»è·ƒç¤¾åŒºJSONæ•°æ®,åŒ…å«:   - ç”¨æˆ·æœ€å¸¸å‘å¸–/è¯„è®ºçš„ç¤¾åŒºåˆ—è¡¨   - æ¯ä¸ªç¤¾åŒºçš„æ´»è·ƒåº¦ä¿¡æ¯   - ç¤¾åŒºåŸºæœ¬ä¿¡æ¯(åç§°ã€å›¾æ ‡ã€æˆå‘˜æ•°ç­‰)  # [English] ### Purpose: - Fetch list of Reddit communities where the specified user is most active ### Parameters: - username: Reddit username ### Returns: - JSON data of user's active communities containing:   - List of communities where user posts/comments most   - Activity level in each community   - Basic community information (name, icon, member count, etc.)  # [ç¤ºä¾‹/Example] username=\"spez\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get_with_http_info(username, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get_with_http_info(username, **kwargs)  # noqa: E501
            return data

    def fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get_with_http_info(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·æ´»è·ƒçš„ç¤¾åŒºåˆ—è¡¨/Fetch User's Active Subreddits  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šç”¨æˆ·æœ€æ´»è·ƒçš„Redditç¤¾åŒºåˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å ### è¿”å›: - ç”¨æˆ·æ´»è·ƒç¤¾åŒºJSONæ•°æ®,åŒ…å«:   - ç”¨æˆ·æœ€å¸¸å‘å¸–/è¯„è®ºçš„ç¤¾åŒºåˆ—è¡¨   - æ¯ä¸ªç¤¾åŒºçš„æ´»è·ƒåº¦ä¿¡æ¯   - ç¤¾åŒºåŸºæœ¬ä¿¡æ¯(åç§°ã€å›¾æ ‡ã€æˆå‘˜æ•°ç­‰)  # [English] ### Purpose: - Fetch list of Reddit communities where the specified user is most active ### Parameters: - username: Reddit username ### Returns: - JSON data of user's active communities containing:   - List of communities where user posts/comments most   - Activity level in each community   - Basic community information (name, icon, member count, etc.)  # [ç¤ºä¾‹/Example] username=\"spez\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get_with_http_info(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['username', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'username' is set
        if self.api_client.client_side_validation and ('username' not in params or
                                                       params['username'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `username` when calling `fetch_user_active_subreddits_api_v1_reddit_app_fetch_user_active_subreddits_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'username' in params:
            query_params.append(('username', params['username']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_user_active_subreddits', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·è¯„è®ºåˆ—è¡¨/Fetch User Comments  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šç”¨æˆ·å‘è¡¨çš„è¯„è®ºåˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å - sort: æ’åºæ–¹å¼,å¯é€‰å€¼: NEW(æœ€æ–°), TOP(æœ€çƒ­), HOT(çƒ­é—¨), CONTROVERSIAL(æœ‰äº‰è®®) - page_size: æ¯é¡µè¿”å›çš„è¯„è®ºæ•°é‡,é»˜è®¤25æ¡ - after: åˆ†é¡µå‚æ•°,ç”¨äºè·å–ä¸‹ä¸€é¡µ ### è¿”å›: - ç”¨æˆ·è¯„è®ºåˆ—è¡¨JSONæ•°æ®,åŒ…å«:   - è¯„è®ºå†…å®¹   - è¯„è®ºæ‰€åœ¨çš„å¸–å­ä¿¡æ¯   - è¯„è®ºæ—¶é—´   - ç‚¹èµæ•°   - å›å¤æ•°   - åˆ†é¡µä¿¡æ¯  # [English] ### Purpose: - Fetch list of comments posted by the specified user ### Parameters: - username: Reddit username - sort: Sort method, options: NEW (newest), TOP (top rated), HOT (hot), CONTROVERSIAL (controversial) - page_size: Number of comments per page, default 25 - after: Pagination parameter for fetching next page ### Returns: - JSON data of user comments containing:   - Comment content   - Information about the post where comment was made   - Comment timestamp   - Upvote count   - Reply count   - Pagination information  # [ç¤ºä¾‹/Example] username=\"spez\" sort=\"NEW\" page_size=25 after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object sort: æ’åºæ–¹å¼/Sort method: NEW, TOP, HOT, CONTROVERSIAL
        :param object page_size: æ¯é¡µæ•°é‡/Page size (default: 25)
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get_with_http_info(username, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get_with_http_info(username, **kwargs)  # noqa: E501
            return data

    def fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get_with_http_info(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·è¯„è®ºåˆ—è¡¨/Fetch User Comments  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šç”¨æˆ·å‘è¡¨çš„è¯„è®ºåˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å - sort: æ’åºæ–¹å¼,å¯é€‰å€¼: NEW(æœ€æ–°), TOP(æœ€çƒ­), HOT(çƒ­é—¨), CONTROVERSIAL(æœ‰äº‰è®®) - page_size: æ¯é¡µè¿”å›çš„è¯„è®ºæ•°é‡,é»˜è®¤25æ¡ - after: åˆ†é¡µå‚æ•°,ç”¨äºè·å–ä¸‹ä¸€é¡µ ### è¿”å›: - ç”¨æˆ·è¯„è®ºåˆ—è¡¨JSONæ•°æ®,åŒ…å«:   - è¯„è®ºå†…å®¹   - è¯„è®ºæ‰€åœ¨çš„å¸–å­ä¿¡æ¯   - è¯„è®ºæ—¶é—´   - ç‚¹èµæ•°   - å›å¤æ•°   - åˆ†é¡µä¿¡æ¯  # [English] ### Purpose: - Fetch list of comments posted by the specified user ### Parameters: - username: Reddit username - sort: Sort method, options: NEW (newest), TOP (top rated), HOT (hot), CONTROVERSIAL (controversial) - page_size: Number of comments per page, default 25 - after: Pagination parameter for fetching next page ### Returns: - JSON data of user comments containing:   - Comment content   - Information about the post where comment was made   - Comment timestamp   - Upvote count   - Reply count   - Pagination information  # [ç¤ºä¾‹/Example] username=\"spez\" sort=\"NEW\" page_size=25 after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get_with_http_info(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object sort: æ’åºæ–¹å¼/Sort method: NEW, TOP, HOT, CONTROVERSIAL
        :param object page_size: æ¯é¡µæ•°é‡/Page size (default: 25)
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['username', 'sort', 'page_size', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'username' is set
        if self.api_client.client_side_validation and ('username' not in params or
                                                       params['username'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `username` when calling `fetch_user_comments_api_v1_reddit_app_fetch_user_comments_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'username' in params:
            query_params.append(('username', params['username']))  # noqa: E501
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'page_size' in params:
            query_params.append(('page_size', params['page_size']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_user_comments', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·å‘å¸ƒçš„å¸–å­åˆ—è¡¨/Fetch User Posts  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šç”¨æˆ·å‘å¸ƒçš„å¸–å­åˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å - sort: æ’åºæ–¹å¼,å¯é€‰å€¼: NEW(æœ€æ–°), TOP(æœ€çƒ­), HOT(çƒ­é—¨), CONTROVERSIAL(æœ‰äº‰è®®) - after: åˆ†é¡µå‚æ•°,ç”¨äºè·å–ä¸‹ä¸€é¡µ ### è¿”å›: - ç”¨æˆ·å¸–å­åˆ—è¡¨JSONæ•°æ®,åŒ…å«:   - å¸–å­æ ‡é¢˜å’Œå†…å®¹   - å‘å¸ƒæ—¶é—´   - æ‰€å±ç‰ˆå—   - ç‚¹èµæ•°å’Œè¯„è®ºæ•°   - å¸–å­ç±»å‹(æ–‡æœ¬/å›¾ç‰‡/è§†é¢‘/é“¾æ¥)   - åª’ä½“å†…å®¹(å¦‚æœ‰)   - åˆ†é¡µä¿¡æ¯  # [English] ### Purpose: - Fetch list of posts submitted by the specified user ### Parameters: - username: Reddit username - sort: Sort method, options: NEW (newest), TOP (top rated), HOT (hot), CONTROVERSIAL (controversial) - after: Pagination parameter for fetching next page ### Returns: - JSON data of user posts containing:   - Post title and content   - Submission time   - Subreddit   - Upvote and comment counts   - Post type (text/image/video/link)   - Media content (if any)   - Pagination information  # [ç¤ºä¾‹/Example] username=\"spez\" sort=\"NEW\" after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object sort: æ’åºæ–¹å¼/Sort method: NEW, TOP, HOT, CONTROVERSIAL
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get_with_http_info(username, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get_with_http_info(username, **kwargs)  # noqa: E501
            return data

    def fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get_with_http_info(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·å‘å¸ƒçš„å¸–å­åˆ—è¡¨/Fetch User Posts  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šç”¨æˆ·å‘å¸ƒçš„å¸–å­åˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å - sort: æ’åºæ–¹å¼,å¯é€‰å€¼: NEW(æœ€æ–°), TOP(æœ€çƒ­), HOT(çƒ­é—¨), CONTROVERSIAL(æœ‰äº‰è®®) - after: åˆ†é¡µå‚æ•°,ç”¨äºè·å–ä¸‹ä¸€é¡µ ### è¿”å›: - ç”¨æˆ·å¸–å­åˆ—è¡¨JSONæ•°æ®,åŒ…å«:   - å¸–å­æ ‡é¢˜å’Œå†…å®¹   - å‘å¸ƒæ—¶é—´   - æ‰€å±ç‰ˆå—   - ç‚¹èµæ•°å’Œè¯„è®ºæ•°   - å¸–å­ç±»å‹(æ–‡æœ¬/å›¾ç‰‡/è§†é¢‘/é“¾æ¥)   - åª’ä½“å†…å®¹(å¦‚æœ‰)   - åˆ†é¡µä¿¡æ¯  # [English] ### Purpose: - Fetch list of posts submitted by the specified user ### Parameters: - username: Reddit username - sort: Sort method, options: NEW (newest), TOP (top rated), HOT (hot), CONTROVERSIAL (controversial) - after: Pagination parameter for fetching next page ### Returns: - JSON data of user posts containing:   - Post title and content   - Submission time   - Subreddit   - Upvote and comment counts   - Post type (text/image/video/link)   - Media content (if any)   - Pagination information  # [ç¤ºä¾‹/Example] username=\"spez\" sort=\"NEW\" after=\"\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get_with_http_info(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object sort: æ’åºæ–¹å¼/Sort method: NEW, TOP, HOT, CONTROVERSIAL
        :param object after: åˆ†é¡µå‚æ•°/Pagination parameter
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['username', 'sort', 'after', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'username' is set
        if self.api_client.client_side_validation and ('username' not in params or
                                                       params['username'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `username` when calling `fetch_user_posts_api_v1_reddit_app_fetch_user_posts_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'username' in params:
            query_params.append(('username', params['username']))  # noqa: E501
        if 'sort' in params:
            query_params.append(('sort', params['sort']))  # noqa: E501
        if 'after' in params:
            query_params.append(('after', params['after']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_user_posts', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get(self, username, **kwargs):  # noqa: E501
        """è·å–Reddit APPç”¨æˆ·èµ„æ–™ä¿¡æ¯/Fetch Reddit APP User Profile  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç”¨æˆ·çš„è¯¦ç»†èµ„æ–™ä¿¡æ¯ ### å‚æ•°: - username: Redditç”¨æˆ·å(ä¸å¸¦u/å‰ç¼€) ### è¿”å›: - ç”¨æˆ·èµ„æ–™JSONæ•°æ®,åŒ…å«:   - ç”¨æˆ·åå’ŒID   - è´¦å·åˆ›å»ºæ—¶é—´   - Karmaå€¼(å¸–å­karmaå’Œè¯„è®ºkarma)   - å¤´åƒå’Œæ¨ªå¹…å›¾ç‰‡   - ä¸ªäººç®€ä»‹   - æ˜¯å¦éªŒè¯è´¦å·   - å¾½ç« å’Œå¥–åŠ±   - å…³æ³¨è€…æ•°é‡  # [English] ### Purpose: - Fetch detailed profile information of a specified Reddit APP user ### Parameters: - username: Reddit username (without u/ prefix) ### Returns: - JSON data of user profile containing:   - Username and ID   - Account creation date   - Karma values (post karma and comment karma)   - Avatar and banner images   - Bio/description   - Verification status   - Badges and awards   - Follower count  # [ç¤ºä¾‹/Example] username=\"spez\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get_with_http_info(username, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get_with_http_info(username, **kwargs)  # noqa: E501
            return data

    def fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get_with_http_info(self, username, **kwargs):  # noqa: E501
        """è·å–Reddit APPç”¨æˆ·èµ„æ–™ä¿¡æ¯/Fetch Reddit APP User Profile  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–Reddit APPæŒ‡å®šç”¨æˆ·çš„è¯¦ç»†èµ„æ–™ä¿¡æ¯ ### å‚æ•°: - username: Redditç”¨æˆ·å(ä¸å¸¦u/å‰ç¼€) ### è¿”å›: - ç”¨æˆ·èµ„æ–™JSONæ•°æ®,åŒ…å«:   - ç”¨æˆ·åå’ŒID   - è´¦å·åˆ›å»ºæ—¶é—´   - Karmaå€¼(å¸–å­karmaå’Œè¯„è®ºkarma)   - å¤´åƒå’Œæ¨ªå¹…å›¾ç‰‡   - ä¸ªäººç®€ä»‹   - æ˜¯å¦éªŒè¯è´¦å·   - å¾½ç« å’Œå¥–åŠ±   - å…³æ³¨è€…æ•°é‡  # [English] ### Purpose: - Fetch detailed profile information of a specified Reddit APP user ### Parameters: - username: Reddit username (without u/ prefix) ### Returns: - JSON data of user profile containing:   - Username and ID   - Account creation date   - Karma values (post karma and comment karma)   - Avatar and banner images   - Bio/description   - Verification status   - Badges and awards   - Follower count  # [ç¤ºä¾‹/Example] username=\"spez\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get_with_http_info(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['username', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'username' is set
        if self.api_client.client_side_validation and ('username' not in params or
                                                       params['username'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `username` when calling `fetch_user_profile_api_v1_reddit_app_fetch_user_profile_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'username' in params:
            query_params.append(('username', params['username']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_user_profile', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·å…¬å¼€å¥–æ¯/Fetch User Public Trophies  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šRedditç”¨æˆ·çš„å…¬å¼€å¥–æ¯/æˆå°±åˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å(ä¸å¸¦u/å‰ç¼€) ### è¿”å›: - ç”¨æˆ·å¥–æ¯JSONæ•°æ®,åŒ…å«:   - å¥–æ¯åˆ—è¡¨(trophy list)   - æ¯ä¸ªå¥–æ¯çš„è¯¦ç»†ä¿¡æ¯:     - å¥–æ¯åç§°     - å¥–æ¯æè¿°     - å¥–æ¯å›¾æ ‡URL     - è·å¾—æ—¶é—´   - ç‰¹æ®Šå¾½ç« å’Œæˆå°±  # [English] ### Purpose: - Fetch public trophies/achievements list of a specified Reddit user ### Parameters: - username: Reddit username (without u/ prefix) ### Returns: - JSON data of user trophies containing:   - Trophy list   - Detailed information for each trophy:     - Trophy name     - Trophy description     - Trophy icon URL     - Award date   - Special badges and achievements  # [ç¤ºä¾‹/Example] username=\"spez\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get_with_http_info(username, **kwargs)  # noqa: E501
        else:
            (data) = self.fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get_with_http_info(username, **kwargs)  # noqa: E501
            return data

    def fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get_with_http_info(self, username, **kwargs):  # noqa: E501
        """è·å–ç”¨æˆ·å…¬å¼€å¥–æ¯/Fetch User Public Trophies  # noqa: E501

        # [ä¸­æ–‡] ### ç”¨é€”: - è·å–æŒ‡å®šRedditç”¨æˆ·çš„å…¬å¼€å¥–æ¯/æˆå°±åˆ—è¡¨ ### å‚æ•°: - username: Redditç”¨æˆ·å(ä¸å¸¦u/å‰ç¼€) ### è¿”å›: - ç”¨æˆ·å¥–æ¯JSONæ•°æ®,åŒ…å«:   - å¥–æ¯åˆ—è¡¨(trophy list)   - æ¯ä¸ªå¥–æ¯çš„è¯¦ç»†ä¿¡æ¯:     - å¥–æ¯åç§°     - å¥–æ¯æè¿°     - å¥–æ¯å›¾æ ‡URL     - è·å¾—æ—¶é—´   - ç‰¹æ®Šå¾½ç« å’Œæˆå°±  # [English] ### Purpose: - Fetch public trophies/achievements list of a specified Reddit user ### Parameters: - username: Reddit username (without u/ prefix) ### Returns: - JSON data of user trophies containing:   - Trophy list   - Detailed information for each trophy:     - Trophy name     - Trophy description     - Trophy icon URL     - Award date   - Special badges and achievements  # [ç¤ºä¾‹/Example] username=\"spez\"  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get_with_http_info(username, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param object username: ç”¨æˆ·å/Username (required)
        :param object need_format: æ˜¯å¦éœ€è¦æ¸…æ´—æ•°æ®/Whether to clean and format the data
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['username', 'need_format']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'username' is set
        if self.api_client.client_side_validation and ('username' not in params or
                                                       params['username'] is None):  # noqa: E501
            raise ValueError("Missing the required parameter `username` when calling `fetch_user_trophies_api_v1_reddit_app_fetch_user_trophies_get`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'username' in params:
            query_params.append(('username', params['username']))  # noqa: E501
        if 'need_format' in params:
            query_params.append(('need_format', params['need_format']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/reddit/app/fetch_user_trophies', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)
